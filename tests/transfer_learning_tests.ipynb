{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# fix bug for the correct use of Conv2D layers\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from helpers import normalize_img, mask_to_categorical\n",
    "from model_setup import training_fit_loop\n",
    "from config_loader import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 13:24:49.296119: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-19 13:24:49.302020: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-19 13:24:49.303589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.62GHz coreCount: 72 deviceMemorySize: 44.49GiB deviceMemoryBandwidth: 581.23GiB/s\n",
      "2022-07-19 13:24:49.303651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-19 13:24:49.303682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-19 13:24:49.303694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-07-19 13:24:49.303705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-19 13:24:49.303716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-19 13:24:49.303726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-19 13:24:49.303737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-19 13:24:49.303747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-19 13:24:49.306381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-19 13:24:49.306414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-19 13:24:49.912771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-19 13:24:49.912805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-07-19 13:24:49.912849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-07-19 13:24:49.916808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42531 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights=None)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(32, 32, 3), name=\"input_layer\")\n",
    "x = base_model(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\",\n",
    "                               name=\"output_layer\")(x)\n",
    "\n",
    "model_0 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 13:24:54.919871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-19 13:24:54.948372: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n",
      "2022-07-19 13:24:56.164095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-19 13:24:56.719808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 12s 75ms/step - loss: 3.2364 - accuracy: 0.1842 - val_loss: 2.4174 - val_accuracy: 0.1034\n",
      "Epoch 2/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 1.8830 - accuracy: 0.3475 - val_loss: 2.7393 - val_accuracy: 0.1034\n",
      "Epoch 3/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 1.5890 - accuracy: 0.4641 - val_loss: 3.0074 - val_accuracy: 0.1130\n",
      "Epoch 4/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.3928 - accuracy: 0.5423 - val_loss: 3.4181 - val_accuracy: 0.1218\n",
      "Epoch 5/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.2712 - accuracy: 0.5711 - val_loss: 2.9716 - val_accuracy: 0.1626\n",
      "Epoch 6/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.3571 - accuracy: 0.5875 - val_loss: 2.7504 - val_accuracy: 0.1978\n",
      "Epoch 7/120\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.0015 - accuracy: 0.6924 - val_loss: 10.7488 - val_accuracy: 0.2504\n",
      "Epoch 8/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.3471 - accuracy: 0.5570 - val_loss: 3.4299 - val_accuracy: 0.2198\n",
      "Epoch 9/120\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.2379 - accuracy: 0.6308 - val_loss: 44.4723 - val_accuracy: 0.1108\n",
      "Epoch 10/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.5996 - accuracy: 0.4734 - val_loss: 2.5309 - val_accuracy: 0.3264\n",
      "Epoch 11/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.3277 - accuracy: 0.5881 - val_loss: 92.2405 - val_accuracy: 0.2138\n",
      "Epoch 12/120\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.5833 - accuracy: 0.5167 - val_loss: 5.2470 - val_accuracy: 0.3318\n",
      "Epoch 13/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.2800 - accuracy: 0.5954 - val_loss: 2.8224 - val_accuracy: 0.2286\n",
      "Epoch 14/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.5503 - accuracy: 0.5250 - val_loss: 1.9859 - val_accuracy: 0.3482\n",
      "Epoch 15/120\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 1.1988 - accuracy: 0.6148 - val_loss: 1.9184 - val_accuracy: 0.4028\n",
      "Epoch 16/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.0074 - accuracy: 0.7014 - val_loss: 14.3815 - val_accuracy: 0.3374\n",
      "Epoch 17/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.5363 - accuracy: 0.5301 - val_loss: 53.1438 - val_accuracy: 0.2976\n",
      "Epoch 18/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.2428 - accuracy: 0.5954 - val_loss: 8.6385 - val_accuracy: 0.4142\n",
      "Epoch 19/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.9147 - accuracy: 0.7016 - val_loss: 2.8974 - val_accuracy: 0.2702\n",
      "Epoch 20/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 1.3173 - accuracy: 0.6318 - val_loss: 6.2777 - val_accuracy: 0.1048\n",
      "Epoch 21/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.4928 - accuracy: 0.5239 - val_loss: 2.8557 - val_accuracy: 0.2240\n",
      "Epoch 22/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.5521 - accuracy: 0.5441 - val_loss: 11546.9639 - val_accuracy: 0.0952\n",
      "Epoch 23/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.5418 - accuracy: 0.4862 - val_loss: 59.9200 - val_accuracy: 0.2778\n",
      "Epoch 24/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.1650 - accuracy: 0.6075 - val_loss: 3.0674 - val_accuracy: 0.3432\n",
      "Epoch 25/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.0657 - accuracy: 0.6621 - val_loss: 9.1800 - val_accuracy: 0.3068\n",
      "Epoch 26/120\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.8618 - accuracy: 0.7459 - val_loss: 2.9099 - val_accuracy: 0.3578\n",
      "Epoch 27/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.8248 - accuracy: 0.7314 - val_loss: 2.0006 - val_accuracy: 0.4506\n",
      "Epoch 28/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.6401 - accuracy: 0.8122 - val_loss: 191.3599 - val_accuracy: 0.1208\n",
      "Epoch 29/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.8839 - accuracy: 0.7448 - val_loss: 2.8063 - val_accuracy: 0.4144\n",
      "Epoch 30/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.4816 - accuracy: 0.8600 - val_loss: 2.5467 - val_accuracy: 0.4700\n",
      "Epoch 31/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.8950 - accuracy: 0.7663 - val_loss: 48.2694 - val_accuracy: 0.0812\n",
      "Epoch 32/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.3736 - accuracy: 0.5512 - val_loss: 8.9657 - val_accuracy: 0.1626\n",
      "Epoch 33/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 1.0391 - accuracy: 0.6430 - val_loss: 2.1535 - val_accuracy: 0.4356\n",
      "Epoch 34/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.6113 - accuracy: 0.8003 - val_loss: 2.0492 - val_accuracy: 0.4508\n",
      "Epoch 35/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.3980 - accuracy: 0.8770 - val_loss: 2.3157 - val_accuracy: 0.4392\n",
      "Epoch 36/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.4086 - accuracy: 0.8753 - val_loss: 3.0070 - val_accuracy: 0.3998\n",
      "Epoch 37/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.5972 - accuracy: 0.8277 - val_loss: 3.3036 - val_accuracy: 0.4114\n",
      "Epoch 38/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.3418 - accuracy: 0.8979 - val_loss: 3.7607 - val_accuracy: 0.3704\n",
      "Epoch 39/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.3795 - accuracy: 0.9034 - val_loss: 2.9084 - val_accuracy: 0.4652\n",
      "Epoch 40/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2497 - accuracy: 0.9420 - val_loss: 2.9523 - val_accuracy: 0.4758\n",
      "Epoch 41/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.2567 - accuracy: 0.9415 - val_loss: 2.9790 - val_accuracy: 0.4916\n",
      "Epoch 42/120\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1605 - accuracy: 0.9572 - val_loss: 2.8605 - val_accuracy: 0.5110\n",
      "Epoch 43/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1425 - accuracy: 0.9686 - val_loss: 3.0597 - val_accuracy: 0.4812\n",
      "Epoch 44/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1377 - accuracy: 0.9694 - val_loss: 3.0601 - val_accuracy: 0.4878\n",
      "Epoch 45/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1629 - accuracy: 0.9633 - val_loss: 3.3310 - val_accuracy: 0.4564\n",
      "Epoch 46/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1454 - accuracy: 0.9561 - val_loss: 3.1710 - val_accuracy: 0.4936\n",
      "Epoch 47/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1040 - accuracy: 0.9710 - val_loss: 3.0689 - val_accuracy: 0.5016\n",
      "Epoch 48/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0942 - accuracy: 0.9772 - val_loss: 3.3383 - val_accuracy: 0.4778\n",
      "Epoch 49/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1275 - accuracy: 0.9623 - val_loss: 3.3151 - val_accuracy: 0.4786\n",
      "Epoch 50/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1495 - accuracy: 0.9597 - val_loss: 9.6517 - val_accuracy: 0.3846\n",
      "Epoch 51/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.2417 - accuracy: 0.9371 - val_loss: 4.9979 - val_accuracy: 0.3388\n",
      "Epoch 52/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.3024 - accuracy: 0.9102 - val_loss: 2.6983 - val_accuracy: 0.5094\n",
      "Epoch 53/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0951 - accuracy: 0.9732 - val_loss: 2.8060 - val_accuracy: 0.5174\n",
      "Epoch 54/120\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.0610 - accuracy: 0.9793 - val_loss: 3.0113 - val_accuracy: 0.5138\n",
      "Epoch 55/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0438 - accuracy: 0.9869 - val_loss: 3.0353 - val_accuracy: 0.5278\n",
      "Epoch 56/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 3.1477 - val_accuracy: 0.5190\n",
      "Epoch 57/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 3.1239 - val_accuracy: 0.5272\n",
      "Epoch 58/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 3.2066 - val_accuracy: 0.5352\n",
      "Epoch 59/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0223 - accuracy: 0.9900 - val_loss: 3.5084 - val_accuracy: 0.5100\n",
      "Epoch 60/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0605 - accuracy: 0.9780 - val_loss: 3.4586 - val_accuracy: 0.5084\n",
      "Epoch 61/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0827 - accuracy: 0.9721 - val_loss: 3.2461 - val_accuracy: 0.5040\n",
      "Epoch 62/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0647 - accuracy: 0.9790 - val_loss: 2.9330 - val_accuracy: 0.5186\n",
      "Epoch 63/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 2.8880 - val_accuracy: 0.5386\n",
      "Epoch 64/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 3.2151 - val_accuracy: 0.5008\n",
      "Epoch 65/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 3.0958 - val_accuracy: 0.5138\n",
      "Epoch 66/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0554 - accuracy: 0.9802 - val_loss: 3.1542 - val_accuracy: 0.5192\n",
      "Epoch 67/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0692 - accuracy: 0.9794 - val_loss: 3.1147 - val_accuracy: 0.4976\n",
      "Epoch 68/120\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 3.1140 - val_accuracy: 0.5170\n",
      "Epoch 69/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0503 - accuracy: 0.9814 - val_loss: 3.4877 - val_accuracy: 0.4680\n",
      "Epoch 70/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0516 - accuracy: 0.9851 - val_loss: 3.2227 - val_accuracy: 0.5034\n",
      "Epoch 71/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 2.9593 - val_accuracy: 0.5224\n",
      "Epoch 72/120\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 3.1413 - val_accuracy: 0.5148\n",
      "Epoch 73/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 3.1861 - val_accuracy: 0.4960\n",
      "Epoch 74/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0803 - accuracy: 0.9746 - val_loss: 3.0547 - val_accuracy: 0.5242\n",
      "Epoch 75/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 3.0882 - val_accuracy: 0.5156\n",
      "Epoch 76/120\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0594 - accuracy: 0.9803 - val_loss: 3.0172 - val_accuracy: 0.5200\n",
      "Epoch 77/120\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0568 - accuracy: 0.9814 - val_loss: 3.0078 - val_accuracy: 0.5118\n",
      "Epoch 78/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 3.3746 - val_accuracy: 0.5016\n",
      "Epoch 79/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 3.1653 - val_accuracy: 0.5036\n",
      "Epoch 80/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0535 - accuracy: 0.9797 - val_loss: 3.1456 - val_accuracy: 0.4864\n",
      "Epoch 81/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 3.0595 - val_accuracy: 0.5110\n",
      "Epoch 82/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 3.1260 - val_accuracy: 0.5280\n",
      "Epoch 83/120\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.0518 - accuracy: 0.9826 - val_loss: 3.0113 - val_accuracy: 0.5240\n",
      "Epoch 84/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0514 - accuracy: 0.9830 - val_loss: 3.2514 - val_accuracy: 0.5076\n",
      "Epoch 85/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 3.1083 - val_accuracy: 0.5232\n",
      "Epoch 86/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 3.2122 - val_accuracy: 0.5090\n",
      "Epoch 87/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 3.0897 - val_accuracy: 0.5066\n",
      "Epoch 88/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 3.0740 - val_accuracy: 0.5170\n",
      "Epoch 89/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0858 - accuracy: 0.9717 - val_loss: 2.8748 - val_accuracy: 0.5222\n",
      "Epoch 90/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 2.8922 - val_accuracy: 0.5042\n",
      "Epoch 91/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0689 - accuracy: 0.9823 - val_loss: 2.8877 - val_accuracy: 0.5260\n",
      "Epoch 92/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0433 - accuracy: 0.9850 - val_loss: 3.1904 - val_accuracy: 0.5146\n",
      "Epoch 93/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0353 - accuracy: 0.9872 - val_loss: 3.0373 - val_accuracy: 0.5326\n",
      "Epoch 94/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 3.1032 - val_accuracy: 0.5274\n",
      "Epoch 95/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0565 - accuracy: 0.9835 - val_loss: 3.1868 - val_accuracy: 0.5130\n",
      "Epoch 96/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0787 - accuracy: 0.9746 - val_loss: 2.7579 - val_accuracy: 0.5252\n",
      "Epoch 97/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 2.9738 - val_accuracy: 0.5162\n",
      "Epoch 98/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 3.3195 - val_accuracy: 0.5234\n",
      "Epoch 99/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 3.3485 - val_accuracy: 0.5244\n",
      "Epoch 100/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 3.2090 - val_accuracy: 0.5098\n",
      "Epoch 101/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0751 - accuracy: 0.9736 - val_loss: 3.1330 - val_accuracy: 0.4960\n",
      "Epoch 102/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.9231 - accuracy: 0.7733 - val_loss: 48613.9180 - val_accuracy: 0.1012\n",
      "Epoch 103/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 1.4860 - accuracy: 0.5596 - val_loss: 1696.4606 - val_accuracy: 0.0956\n",
      "Epoch 104/120\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 1.6327 - accuracy: 0.4657 - val_loss: 239.4563 - val_accuracy: 0.1710\n",
      "Epoch 105/120\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 1.1966 - accuracy: 0.6295 - val_loss: 5.1723 - val_accuracy: 0.4500\n",
      "Epoch 106/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.7389 - accuracy: 0.7747 - val_loss: 1.7462 - val_accuracy: 0.4790\n",
      "Epoch 107/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.5015 - accuracy: 0.8613 - val_loss: 1.9530 - val_accuracy: 0.4808\n",
      "Epoch 108/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.3480 - accuracy: 0.8886 - val_loss: 2.4102 - val_accuracy: 0.4426\n",
      "Epoch 109/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.5054 - accuracy: 0.8819 - val_loss: 2.5399 - val_accuracy: 0.4516\n",
      "Epoch 110/120\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.3790 - accuracy: 0.9043 - val_loss: 2.5944 - val_accuracy: 0.5036\n",
      "Epoch 111/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.4667 - accuracy: 0.8992 - val_loss: 3.2562 - val_accuracy: 0.4418\n",
      "Epoch 112/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.3407 - accuracy: 0.9098 - val_loss: 2.8564 - val_accuracy: 0.4926\n",
      "Epoch 113/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1538 - accuracy: 0.9662 - val_loss: 3.1040 - val_accuracy: 0.4324\n",
      "Epoch 114/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1547 - accuracy: 0.9750 - val_loss: 2.8903 - val_accuracy: 0.5098\n",
      "Epoch 115/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 49ms/step - loss: 0.4187 - accuracy: 0.8948 - val_loss: 27.3003 - val_accuracy: 0.2664\n",
      "Epoch 116/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 1.0802 - accuracy: 0.6475 - val_loss: 2.6115 - val_accuracy: 0.4554\n",
      "Epoch 117/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.5077 - accuracy: 0.8421 - val_loss: 2.0114 - val_accuracy: 0.4758\n",
      "Epoch 118/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.3193 - accuracy: 0.9247 - val_loss: 2.3320 - val_accuracy: 0.5018\n",
      "Epoch 119/120\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.3336 - accuracy: 0.9341 - val_loss: 2.2688 - val_accuracy: 0.5176\n",
      "Epoch 120/120\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1785 - accuracy: 0.9532 - val_loss: 2.5022 - val_accuracy: 0.4964\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 2.4514 - accuracy: 0.5058\n",
      "Epoch 1/96\n",
      "79/79 [==============================] - 9s 60ms/step - loss: 3.0627 - accuracy: 0.2031 - val_loss: 2.7443 - val_accuracy: 0.0956\n",
      "Epoch 2/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 1.9756 - accuracy: 0.3307 - val_loss: 2.9802 - val_accuracy: 0.0956\n",
      "Epoch 3/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.6742 - accuracy: 0.4455 - val_loss: 2.8422 - val_accuracy: 0.1136\n",
      "Epoch 4/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.4844 - accuracy: 0.5222 - val_loss: 3.4679 - val_accuracy: 0.1552\n",
      "Epoch 5/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.3165 - accuracy: 0.5473 - val_loss: 2.4987 - val_accuracy: 0.2396\n",
      "Epoch 6/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.1723 - accuracy: 0.5982 - val_loss: 2.6748 - val_accuracy: 0.2676\n",
      "Epoch 7/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.4312 - accuracy: 0.5324 - val_loss: 2.0817 - val_accuracy: 0.3198\n",
      "Epoch 8/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 1.3268 - accuracy: 0.5574 - val_loss: 3.0036 - val_accuracy: 0.3908\n",
      "Epoch 9/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.0817 - accuracy: 0.6549 - val_loss: 2.1690 - val_accuracy: 0.3966\n",
      "Epoch 10/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.9156 - accuracy: 0.7063 - val_loss: 2.9263 - val_accuracy: 0.3678\n",
      "Epoch 11/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.7305 - accuracy: 0.7715 - val_loss: 4.1648 - val_accuracy: 0.2716\n",
      "Epoch 12/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.7109 - accuracy: 0.7805 - val_loss: 67.2952 - val_accuracy: 0.1908\n",
      "Epoch 13/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.9785 - accuracy: 0.6959 - val_loss: 3.3343 - val_accuracy: 0.3388\n",
      "Epoch 14/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 1.8601 - accuracy: 0.5083 - val_loss: 6633189.0000 - val_accuracy: 0.1048\n",
      "Epoch 15/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 2.3859 - accuracy: 0.2277 - val_loss: 380.6938 - val_accuracy: 0.1088\n",
      "Epoch 16/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 2.1126 - accuracy: 0.3347 - val_loss: 3.5755 - val_accuracy: 0.1956\n",
      "Epoch 17/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 1.8771 - accuracy: 0.3875 - val_loss: 2.3209 - val_accuracy: 0.3560\n",
      "Epoch 18/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.7090 - accuracy: 0.4403 - val_loss: 1.6353 - val_accuracy: 0.4198\n",
      "Epoch 19/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 1.6148 - accuracy: 0.4825 - val_loss: 1.6158 - val_accuracy: 0.4302\n",
      "Epoch 20/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.6736 - accuracy: 0.4768 - val_loss: 1.9394 - val_accuracy: 0.3888\n",
      "Epoch 21/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.4741 - accuracy: 0.5213 - val_loss: 2.1892 - val_accuracy: 0.4168\n",
      "Epoch 22/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 1.3682 - accuracy: 0.5805 - val_loss: 1.5758 - val_accuracy: 0.4476\n",
      "Epoch 23/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 1.1629 - accuracy: 0.6237 - val_loss: 2.0788 - val_accuracy: 0.4134\n",
      "Epoch 24/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 1.1089 - accuracy: 0.6443 - val_loss: 1.9070 - val_accuracy: 0.4380\n",
      "Epoch 25/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 1.0361 - accuracy: 0.6825 - val_loss: 1.9369 - val_accuracy: 0.4466\n",
      "Epoch 26/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.9447 - accuracy: 0.6990 - val_loss: 2.1700 - val_accuracy: 0.4414\n",
      "Epoch 27/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.9155 - accuracy: 0.7256 - val_loss: 2.6710 - val_accuracy: 0.4238\n",
      "Epoch 28/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.8033 - accuracy: 0.7477 - val_loss: 2.3157 - val_accuracy: 0.4294\n",
      "Epoch 29/96\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.8516 - accuracy: 0.7615 - val_loss: 2.9058 - val_accuracy: 0.4256\n",
      "Epoch 30/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.6654 - accuracy: 0.7901 - val_loss: 3.1444 - val_accuracy: 0.4070\n",
      "Epoch 31/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.7552 - accuracy: 0.7699 - val_loss: 2.9396 - val_accuracy: 0.4550\n",
      "Epoch 32/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.5892 - accuracy: 0.8247 - val_loss: 2.6879 - val_accuracy: 0.4296\n",
      "Epoch 33/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.8038 - accuracy: 0.7533 - val_loss: 2.8374 - val_accuracy: 0.4448\n",
      "Epoch 34/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.5150 - accuracy: 0.8410 - val_loss: 2.4739 - val_accuracy: 0.4626\n",
      "Epoch 35/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.3656 - accuracy: 0.8934 - val_loss: 2.6717 - val_accuracy: 0.4600\n",
      "Epoch 36/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.3922 - accuracy: 0.8755 - val_loss: 5.1775 - val_accuracy: 0.3694\n",
      "Epoch 37/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.8646 - accuracy: 0.7095 - val_loss: 2.6856 - val_accuracy: 0.4240\n",
      "Epoch 38/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.4913 - accuracy: 0.8475 - val_loss: 3.2475 - val_accuracy: 0.4494\n",
      "Epoch 39/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.3368 - accuracy: 0.9052 - val_loss: 3.6089 - val_accuracy: 0.4166\n",
      "Epoch 40/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.2604 - accuracy: 0.9262 - val_loss: 3.2807 - val_accuracy: 0.4342\n",
      "Epoch 41/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1545 - accuracy: 0.9508 - val_loss: 3.2605 - val_accuracy: 0.4618\n",
      "Epoch 42/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1781 - accuracy: 0.9492 - val_loss: 3.2417 - val_accuracy: 0.4656\n",
      "Epoch 43/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1600 - accuracy: 0.9446 - val_loss: 3.4566 - val_accuracy: 0.4558\n",
      "Epoch 44/96\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.1299 - accuracy: 0.9553 - val_loss: 4.0629 - val_accuracy: 0.4592\n",
      "Epoch 45/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.2352 - accuracy: 0.9282 - val_loss: 3.4626 - val_accuracy: 0.4096\n",
      "Epoch 46/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.7160 - accuracy: 0.8372 - val_loss: 2.7712 - val_accuracy: 0.4122\n",
      "Epoch 47/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 1.5886 - accuracy: 0.5157 - val_loss: 2.5515 - val_accuracy: 0.3344\n",
      "Epoch 48/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 1.3372 - accuracy: 0.5438 - val_loss: 1.7758 - val_accuracy: 0.4506\n",
      "Epoch 49/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.8072 - accuracy: 0.7193 - val_loss: 1.7320 - val_accuracy: 0.4782\n",
      "Epoch 50/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.4326 - accuracy: 0.8492 - val_loss: 2.0847 - val_accuracy: 0.4702\n",
      "Epoch 51/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.3550 - accuracy: 0.8725 - val_loss: 2.6128 - val_accuracy: 0.4310\n",
      "Epoch 52/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.2552 - accuracy: 0.9068 - val_loss: 2.6432 - val_accuracy: 0.4740\n",
      "Epoch 53/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1882 - accuracy: 0.9343 - val_loss: 2.7417 - val_accuracy: 0.4756\n",
      "Epoch 54/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.1569 - accuracy: 0.9426 - val_loss: 3.4597 - val_accuracy: 0.4454\n",
      "Epoch 55/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1166 - accuracy: 0.9615 - val_loss: 3.1849 - val_accuracy: 0.4762\n",
      "Epoch 56/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0869 - accuracy: 0.9691 - val_loss: 3.0737 - val_accuracy: 0.4992\n",
      "Epoch 57/96\n",
      "79/79 [==============================] - 3s 43ms/step - loss: 0.0780 - accuracy: 0.9726 - val_loss: 3.1340 - val_accuracy: 0.5088\n",
      "Epoch 58/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.0805 - accuracy: 0.9735 - val_loss: 3.0730 - val_accuracy: 0.5024\n",
      "Epoch 59/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0917 - accuracy: 0.9692 - val_loss: 3.1433 - val_accuracy: 0.5096\n",
      "Epoch 60/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0664 - accuracy: 0.9777 - val_loss: 3.4215 - val_accuracy: 0.4724\n",
      "Epoch 61/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 3.7647 - val_accuracy: 0.4646\n",
      "Epoch 62/96\n",
      "79/79 [==============================] - 4s 49ms/step - loss: 0.0755 - accuracy: 0.9743 - val_loss: 3.0944 - val_accuracy: 0.4974\n",
      "Epoch 63/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 3.0506 - val_accuracy: 0.5132\n",
      "Epoch 64/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0618 - accuracy: 0.9786 - val_loss: 3.1806 - val_accuracy: 0.5108\n",
      "Epoch 65/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0560 - accuracy: 0.9796 - val_loss: 3.3425 - val_accuracy: 0.5096\n",
      "Epoch 66/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.3316 - accuracy: 0.9128 - val_loss: 2.9859 - val_accuracy: 0.4876\n",
      "Epoch 67/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.1773 - accuracy: 0.9377 - val_loss: 2.8152 - val_accuracy: 0.4880\n",
      "Epoch 68/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0948 - accuracy: 0.9647 - val_loss: 2.7550 - val_accuracy: 0.5222\n",
      "Epoch 69/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 2.8057 - val_accuracy: 0.5264\n",
      "Epoch 70/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0496 - accuracy: 0.9830 - val_loss: 3.2813 - val_accuracy: 0.4952\n",
      "Epoch 71/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 3.3312 - val_accuracy: 0.5070\n",
      "Epoch 72/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 3.0327 - val_accuracy: 0.5236\n",
      "Epoch 73/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0329 - accuracy: 0.9874 - val_loss: 3.3104 - val_accuracy: 0.4876\n",
      "Epoch 74/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0817 - accuracy: 0.9723 - val_loss: 3.0095 - val_accuracy: 0.5216\n",
      "Epoch 75/96\n",
      "79/79 [==============================] - 4s 46ms/step - loss: 0.0476 - accuracy: 0.9833 - val_loss: 3.1252 - val_accuracy: 0.5330\n",
      "Epoch 76/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0514 - accuracy: 0.9818 - val_loss: 3.4486 - val_accuracy: 0.4896\n",
      "Epoch 77/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 2.9060 - val_accuracy: 0.5368\n",
      "Epoch 78/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0626 - accuracy: 0.9759 - val_loss: 3.0314 - val_accuracy: 0.5086\n",
      "Epoch 79/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 3.0813 - val_accuracy: 0.5246\n",
      "Epoch 80/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 3.5656 - val_accuracy: 0.4782\n",
      "Epoch 81/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0704 - accuracy: 0.9774 - val_loss: 3.5886 - val_accuracy: 0.4866\n",
      "Epoch 82/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 2.9005 - val_accuracy: 0.5082\n",
      "Epoch 83/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 3.1362 - val_accuracy: 0.5096\n",
      "Epoch 84/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0646 - accuracy: 0.9772 - val_loss: 2.9334 - val_accuracy: 0.5120\n",
      "Epoch 85/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 2.9394 - val_accuracy: 0.5196\n",
      "Epoch 86/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 3.0265 - val_accuracy: 0.5200\n",
      "Epoch 87/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 3.1926 - val_accuracy: 0.5006\n",
      "Epoch 88/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0816 - accuracy: 0.9753 - val_loss: 3.2788 - val_accuracy: 0.4984\n",
      "Epoch 89/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 3.1893 - val_accuracy: 0.5188\n",
      "Epoch 90/96\n",
      "79/79 [==============================] - 4s 45ms/step - loss: 0.0410 - accuracy: 0.9855 - val_loss: 3.4230 - val_accuracy: 0.5080\n",
      "Epoch 91/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 3.6629 - val_accuracy: 0.4848\n",
      "Epoch 92/96\n",
      "79/79 [==============================] - 3s 44ms/step - loss: 0.0575 - accuracy: 0.9791 - val_loss: 3.2161 - val_accuracy: 0.5088\n",
      "Epoch 93/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.0620 - accuracy: 0.9780 - val_loss: 3.2872 - val_accuracy: 0.5204\n",
      "Epoch 94/96\n",
      "79/79 [==============================] - 4s 47ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 3.0963 - val_accuracy: 0.5042\n",
      "Epoch 95/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.0567 - accuracy: 0.9831 - val_loss: 2.9594 - val_accuracy: 0.5314\n",
      "Epoch 96/96\n",
      "79/79 [==============================] - 4s 44ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 2.8306 - val_accuracy: 0.5268\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 2.8864 - accuracy: 0.5288\n",
      "Epoch 1/80\n",
      "94/94 [==============================] - 10s 57ms/step - loss: 2.9422 - accuracy: 0.1932 - val_loss: 2.5660 - val_accuracy: 0.1060\n",
      "Epoch 2/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.8118 - accuracy: 0.3744 - val_loss: 2.9172 - val_accuracy: 0.1052\n",
      "Epoch 3/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.6653 - accuracy: 0.4337 - val_loss: 658.2660 - val_accuracy: 0.1364\n",
      "Epoch 4/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.7572 - accuracy: 0.4184 - val_loss: 2.4071 - val_accuracy: 0.2086\n",
      "Epoch 5/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.3719 - accuracy: 0.5223 - val_loss: 1.9433 - val_accuracy: 0.3334\n",
      "Epoch 6/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.2504 - accuracy: 0.5883 - val_loss: 1.9881 - val_accuracy: 0.3482\n",
      "Epoch 7/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.1407 - accuracy: 0.6337 - val_loss: 2.0324 - val_accuracy: 0.3738\n",
      "Epoch 8/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.0102 - accuracy: 0.6620 - val_loss: 2.2082 - val_accuracy: 0.3620\n",
      "Epoch 9/80\n",
      "94/94 [==============================] - 5s 49ms/step - loss: 1.3797 - accuracy: 0.5845 - val_loss: 651.6395 - val_accuracy: 0.0966\n",
      "Epoch 10/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.5761 - accuracy: 0.4651 - val_loss: 203.2549 - val_accuracy: 0.1416\n",
      "Epoch 11/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.5280 - accuracy: 0.4976 - val_loss: 1901.8252 - val_accuracy: 0.1014\n",
      "Epoch 12/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.6010 - accuracy: 0.4715 - val_loss: 18.5653 - val_accuracy: 0.3536\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 46ms/step - loss: 1.3071 - accuracy: 0.5678 - val_loss: 42803172.0000 - val_accuracy: 0.1040\n",
      "Epoch 14/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 2.0619 - accuracy: 0.2922 - val_loss: 42.6296 - val_accuracy: 0.1590\n",
      "Epoch 15/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.7207 - accuracy: 0.4177 - val_loss: 3.0206 - val_accuracy: 0.3418\n",
      "Epoch 16/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.6148 - accuracy: 0.4521 - val_loss: 1.6461 - val_accuracy: 0.3906\n",
      "Epoch 17/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.3924 - accuracy: 0.5115 - val_loss: 1.5607 - val_accuracy: 0.4430\n",
      "Epoch 18/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.2274 - accuracy: 0.5760 - val_loss: 1.7270 - val_accuracy: 0.4214\n",
      "Epoch 19/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.1507 - accuracy: 0.6193 - val_loss: 1.7364 - val_accuracy: 0.4332\n",
      "Epoch 20/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.0756 - accuracy: 0.6383 - val_loss: 2.0189 - val_accuracy: 0.4078\n",
      "Epoch 21/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.4125 - accuracy: 0.5527 - val_loss: 2.2680 - val_accuracy: 0.2984\n",
      "Epoch 22/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.5391 - accuracy: 0.4657 - val_loss: 5.8715 - val_accuracy: 0.4192\n",
      "Epoch 23/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.3627 - accuracy: 0.5364 - val_loss: 1.5962 - val_accuracy: 0.4538\n",
      "Epoch 24/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.1695 - accuracy: 0.6118 - val_loss: 1.9269 - val_accuracy: 0.3892\n",
      "Epoch 25/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.2919 - accuracy: 0.5818 - val_loss: 20.6519 - val_accuracy: 0.2514\n",
      "Epoch 26/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 1.6096 - accuracy: 0.4630 - val_loss: 5.5417 - val_accuracy: 0.4444\n",
      "Epoch 27/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.2495 - accuracy: 0.5819 - val_loss: 1.5566 - val_accuracy: 0.4826\n",
      "Epoch 28/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.0465 - accuracy: 0.6558 - val_loss: 1.7756 - val_accuracy: 0.4444\n",
      "Epoch 29/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.8168 - accuracy: 0.7234 - val_loss: 1.9099 - val_accuracy: 0.4510\n",
      "Epoch 30/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.7857 - accuracy: 0.7679 - val_loss: 2.2878 - val_accuracy: 0.4534\n",
      "Epoch 31/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6741 - accuracy: 0.7797 - val_loss: 2.8395 - val_accuracy: 0.4380\n",
      "Epoch 32/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6784 - accuracy: 0.7925 - val_loss: 22.2038 - val_accuracy: 0.4546\n",
      "Epoch 33/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.6647 - accuracy: 0.8018 - val_loss: 3.1663 - val_accuracy: 0.4684\n",
      "Epoch 34/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.6791 - accuracy: 0.8046 - val_loss: 3.8647 - val_accuracy: 0.4608\n",
      "Epoch 35/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6232 - accuracy: 0.8241 - val_loss: 2.4906 - val_accuracy: 0.4080\n",
      "Epoch 36/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.9084 - accuracy: 0.7652 - val_loss: 14.1834 - val_accuracy: 0.3480\n",
      "Epoch 37/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.7434 - accuracy: 0.7829 - val_loss: 2.2557 - val_accuracy: 0.4846\n",
      "Epoch 38/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.8740 - accuracy: 0.7370 - val_loss: 10.5360 - val_accuracy: 0.4194\n",
      "Epoch 39/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 1.1301 - accuracy: 0.6303 - val_loss: 94.5761 - val_accuracy: 0.3538\n",
      "Epoch 40/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.9012 - accuracy: 0.7150 - val_loss: 5.9677 - val_accuracy: 0.4624\n",
      "Epoch 41/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.7796 - accuracy: 0.7550 - val_loss: 2.0618 - val_accuracy: 0.4998\n",
      "Epoch 42/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.5584 - accuracy: 0.8364 - val_loss: 2.2316 - val_accuracy: 0.5264\n",
      "Epoch 43/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.3978 - accuracy: 0.8815 - val_loss: 2.0355 - val_accuracy: 0.5278\n",
      "Epoch 44/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.3628 - accuracy: 0.9032 - val_loss: 3.0298 - val_accuracy: 0.2782\n",
      "Epoch 45/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6273 - accuracy: 0.8305 - val_loss: 9.9725 - val_accuracy: 0.4950\n",
      "Epoch 46/80\n",
      "94/94 [==============================] - 4s 48ms/step - loss: 0.3939 - accuracy: 0.9006 - val_loss: 2.9264 - val_accuracy: 0.4902\n",
      "Epoch 47/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.3650 - accuracy: 0.8973 - val_loss: 2.8205 - val_accuracy: 0.4908\n",
      "Epoch 48/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.4244 - accuracy: 0.8957 - val_loss: 12.7077 - val_accuracy: 0.4028\n",
      "Epoch 49/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.4170 - accuracy: 0.8898 - val_loss: 2.8415 - val_accuracy: 0.4976\n",
      "Epoch 50/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.2529 - accuracy: 0.9425 - val_loss: 2.4683 - val_accuracy: 0.5498\n",
      "Epoch 51/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.1755 - accuracy: 0.9623 - val_loss: 2.9425 - val_accuracy: 0.5048\n",
      "Epoch 52/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.2089 - accuracy: 0.9514 - val_loss: 2.9412 - val_accuracy: 0.4932\n",
      "Epoch 53/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.2269 - accuracy: 0.9399 - val_loss: 4.0495 - val_accuracy: 0.5192\n",
      "Epoch 54/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.2124 - accuracy: 0.9387 - val_loss: 7.2968 - val_accuracy: 0.4924\n",
      "Epoch 55/80\n",
      "94/94 [==============================] - 4s 44ms/step - loss: 0.2211 - accuracy: 0.9548 - val_loss: 2.7393 - val_accuracy: 0.5404\n",
      "Epoch 56/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.1433 - accuracy: 0.9728 - val_loss: 2.7996 - val_accuracy: 0.5270\n",
      "Epoch 57/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.3062 - accuracy: 0.9237 - val_loss: 2.6769 - val_accuracy: 0.5266\n",
      "Epoch 58/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.1751 - accuracy: 0.9567 - val_loss: 3.0049 - val_accuracy: 0.5340\n",
      "Epoch 59/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.1082 - accuracy: 0.9741 - val_loss: 3.2603 - val_accuracy: 0.5110\n",
      "Epoch 60/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.2113 - accuracy: 0.9482 - val_loss: 2564.0054 - val_accuracy: 0.1052\n",
      "Epoch 61/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.9490 - accuracy: 0.7098 - val_loss: 9.1772 - val_accuracy: 0.2826\n",
      "Epoch 62/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 1.1072 - accuracy: 0.6716 - val_loss: 2.3986 - val_accuracy: 0.4506\n",
      "Epoch 63/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6498 - accuracy: 0.8045 - val_loss: 2.3348 - val_accuracy: 0.4980\n",
      "Epoch 64/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.3908 - accuracy: 0.8750 - val_loss: 2.1344 - val_accuracy: 0.5386\n",
      "Epoch 65/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.1767 - accuracy: 0.9459 - val_loss: 2.2625 - val_accuracy: 0.5248\n",
      "Epoch 66/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.1455 - accuracy: 0.9555 - val_loss: 2.5251 - val_accuracy: 0.5412\n",
      "Epoch 67/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.1772 - accuracy: 0.9472 - val_loss: 2.6976 - val_accuracy: 0.5306\n",
      "Epoch 68/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.1030 - accuracy: 0.9666 - val_loss: 2.8440 - val_accuracy: 0.5426\n",
      "Epoch 69/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0880 - accuracy: 0.9717 - val_loss: 5.9373 - val_accuracy: 0.4978\n",
      "Epoch 70/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.3127 - accuracy: 0.9336 - val_loss: 3.6505 - val_accuracy: 0.4370\n",
      "Epoch 71/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.6163 - accuracy: 0.8034 - val_loss: 2.0673 - val_accuracy: 0.5258\n",
      "Epoch 72/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.2241 - accuracy: 0.9228 - val_loss: 2.2157 - val_accuracy: 0.5544\n",
      "Epoch 73/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0642 - accuracy: 0.9773 - val_loss: 2.4956 - val_accuracy: 0.5598\n",
      "Epoch 74/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 2.6924 - val_accuracy: 0.5624\n",
      "Epoch 75/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 2.9589 - val_accuracy: 0.5710\n",
      "Epoch 76/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 3.2143 - val_accuracy: 0.5646\n",
      "Epoch 77/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 3.2765 - val_accuracy: 0.5624\n",
      "Epoch 78/80\n",
      "94/94 [==============================] - 4s 46ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 3.2338 - val_accuracy: 0.5444\n",
      "Epoch 79/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0704 - accuracy: 0.9773 - val_loss: 3.2688 - val_accuracy: 0.5542\n",
      "Epoch 80/80\n",
      "94/94 [==============================] - 4s 45ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 3.1027 - val_accuracy: 0.5594\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 3.0736 - accuracy: 0.5568\n",
      "Epoch 1/68\n",
      "110/110 [==============================] - 11s 54ms/step - loss: 2.8488 - accuracy: 0.2000 - val_loss: 2.6872 - val_accuracy: 0.1034\n",
      "Epoch 2/68\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.7595 - accuracy: 0.3920 - val_loss: 3.1028 - val_accuracy: 0.1218\n",
      "Epoch 3/68\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.7299 - accuracy: 0.4051 - val_loss: 2.4956 - val_accuracy: 0.2128\n",
      "Epoch 4/68\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.6502 - accuracy: 0.4368 - val_loss: 3.9275 - val_accuracy: 0.2692\n",
      "Epoch 5/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.4542 - accuracy: 0.5027 - val_loss: 1.9706 - val_accuracy: 0.3228\n",
      "Epoch 6/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.6128 - accuracy: 0.4495 - val_loss: 2.7398 - val_accuracy: 0.3146\n",
      "Epoch 7/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.4630 - accuracy: 0.5048 - val_loss: 1.5569 - val_accuracy: 0.4522\n",
      "Epoch 8/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.5458 - accuracy: 0.5025 - val_loss: 19.5375 - val_accuracy: 0.2108\n",
      "Epoch 9/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.5572 - accuracy: 0.4850 - val_loss: 4.0190 - val_accuracy: 0.2802\n",
      "Epoch 10/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.4487 - accuracy: 0.5125 - val_loss: 1.5161 - val_accuracy: 0.4694\n",
      "Epoch 11/68\n",
      "110/110 [==============================] - 5s 41ms/step - loss: 1.1972 - accuracy: 0.5989 - val_loss: 2.3343 - val_accuracy: 0.2748\n",
      "Epoch 12/68\n",
      "110/110 [==============================] - 4s 41ms/step - loss: 1.3375 - accuracy: 0.5427 - val_loss: 1.6167 - val_accuracy: 0.4950\n",
      "Epoch 13/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.0278 - accuracy: 0.6590 - val_loss: 2.1275 - val_accuracy: 0.5144\n",
      "Epoch 14/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.9430 - accuracy: 0.7112 - val_loss: 1.8761 - val_accuracy: 0.4390\n",
      "Epoch 15/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.9767 - accuracy: 0.6899 - val_loss: 1.7045 - val_accuracy: 0.5168\n",
      "Epoch 16/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.8542 - accuracy: 0.7372 - val_loss: 1.9156 - val_accuracy: 0.4574\n",
      "Epoch 17/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.8938 - accuracy: 0.7148 - val_loss: 1.6946 - val_accuracy: 0.5180\n",
      "Epoch 18/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.7200 - accuracy: 0.7664 - val_loss: 2.0527 - val_accuracy: 0.4302\n",
      "Epoch 19/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.9452 - accuracy: 0.7273 - val_loss: 25.1330 - val_accuracy: 0.3926\n",
      "Epoch 20/68\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.9026 - accuracy: 0.7221 - val_loss: 5.6539 - val_accuracy: 0.4384\n",
      "Epoch 21/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.5607 - accuracy: 0.8286 - val_loss: 7.2543 - val_accuracy: 0.4058\n",
      "Epoch 22/68\n",
      "110/110 [==============================] - 5s 41ms/step - loss: 0.7148 - accuracy: 0.7706 - val_loss: 3.0535 - val_accuracy: 0.2806\n",
      "Epoch 23/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.7806 - accuracy: 0.7343 - val_loss: 2.6289 - val_accuracy: 0.4348\n",
      "Epoch 24/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.0616 - accuracy: 0.6869 - val_loss: 7.5937 - val_accuracy: 0.3274\n",
      "Epoch 25/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.7575 - accuracy: 0.7711 - val_loss: 2.0015 - val_accuracy: 0.4462\n",
      "Epoch 26/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.9431 - accuracy: 0.3888 - val_loss: 2.7426 - val_accuracy: 0.1114\n",
      "Epoch 27/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 2.2741 - accuracy: 0.3596 - val_loss: 45.8028 - val_accuracy: 0.2996\n",
      "Epoch 28/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.7248 - accuracy: 0.4331 - val_loss: 2.1500 - val_accuracy: 0.2602\n",
      "Epoch 29/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.8805 - accuracy: 0.4154 - val_loss: 5.6745 - val_accuracy: 0.4236\n",
      "Epoch 30/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.4490 - accuracy: 0.5165 - val_loss: 1.7445 - val_accuracy: 0.4250\n",
      "Epoch 31/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.2771 - accuracy: 0.5647 - val_loss: 1.7288 - val_accuracy: 0.4886\n",
      "Epoch 32/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.1052 - accuracy: 0.6236 - val_loss: 1.4325 - val_accuracy: 0.5098\n",
      "Epoch 33/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.9997 - accuracy: 0.6692 - val_loss: 1.4892 - val_accuracy: 0.5128\n",
      "Epoch 34/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8537 - accuracy: 0.7211 - val_loss: 14.8718 - val_accuracy: 0.3970\n",
      "Epoch 35/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.9861 - accuracy: 0.6921 - val_loss: 1.7161 - val_accuracy: 0.4932\n",
      "Epoch 36/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8594 - accuracy: 0.7298 - val_loss: 1.9231 - val_accuracy: 0.4534\n",
      "Epoch 37/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.7581 - accuracy: 0.7597 - val_loss: 2.0368 - val_accuracy: 0.5264\n",
      "Epoch 38/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.5679 - accuracy: 0.8327 - val_loss: 2.1551 - val_accuracy: 0.4990\n",
      "Epoch 39/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.4560 - accuracy: 0.8581 - val_loss: 2.0560 - val_accuracy: 0.5350\n",
      "Epoch 40/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.3628 - accuracy: 0.8794 - val_loss: 2.2805 - val_accuracy: 0.5194\n",
      "Epoch 41/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.4414 - accuracy: 0.8694 - val_loss: 2.1316 - val_accuracy: 0.5502\n",
      "Epoch 42/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.2799 - accuracy: 0.9094 - val_loss: 2.1300 - val_accuracy: 0.5472\n",
      "Epoch 43/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.2281 - accuracy: 0.9271 - val_loss: 2.3719 - val_accuracy: 0.5252\n",
      "Epoch 44/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.3678 - accuracy: 0.8965 - val_loss: 2.0422 - val_accuracy: 0.5404\n",
      "Epoch 45/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.3200 - accuracy: 0.9229 - val_loss: 2.2464 - val_accuracy: 0.5624\n",
      "Epoch 46/68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 5s 43ms/step - loss: 0.1896 - accuracy: 0.9390 - val_loss: 3.5260 - val_accuracy: 0.5290\n",
      "Epoch 47/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.2112 - accuracy: 0.9395 - val_loss: 2.2823 - val_accuracy: 0.5608\n",
      "Epoch 48/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.1627 - accuracy: 0.9551 - val_loss: 2.4902 - val_accuracy: 0.5574\n",
      "Epoch 49/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8179 - accuracy: 0.7814 - val_loss: 147.9801 - val_accuracy: 0.1764\n",
      "Epoch 50/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.9905 - accuracy: 0.6825 - val_loss: 2.1714 - val_accuracy: 0.5036\n",
      "Epoch 51/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.5795 - accuracy: 0.8342 - val_loss: 10.0531 - val_accuracy: 0.3896\n",
      "Epoch 52/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.5365 - accuracy: 0.8432 - val_loss: 1.7969 - val_accuracy: 0.5574\n",
      "Epoch 53/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.2635 - accuracy: 0.9361 - val_loss: 2.1547 - val_accuracy: 0.5664\n",
      "Epoch 54/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.2418 - accuracy: 0.9328 - val_loss: 3.2446 - val_accuracy: 0.3850\n",
      "Epoch 55/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.6326 - accuracy: 0.8002 - val_loss: 4.2855 - val_accuracy: 0.4176\n",
      "Epoch 56/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.0117 - accuracy: 0.6807 - val_loss: 4.6261 - val_accuracy: 0.2510\n",
      "Epoch 57/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.7349 - accuracy: 0.4466 - val_loss: 10.8847 - val_accuracy: 0.2066\n",
      "Epoch 58/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.7739 - accuracy: 0.4154 - val_loss: 7.8444 - val_accuracy: 0.3250\n",
      "Epoch 59/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.5310 - accuracy: 0.4873 - val_loss: 6.1418 - val_accuracy: 0.4146\n",
      "Epoch 60/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.3442 - accuracy: 0.5566 - val_loss: 1.9483 - val_accuracy: 0.3810\n",
      "Epoch 61/68\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.2855 - accuracy: 0.6011 - val_loss: 1.4950 - val_accuracy: 0.5102\n",
      "Epoch 62/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.1398 - accuracy: 0.6549 - val_loss: 1.6005 - val_accuracy: 0.4598\n",
      "Epoch 63/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 1.2506 - accuracy: 0.5892 - val_loss: 1.3926 - val_accuracy: 0.5230\n",
      "Epoch 64/68\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 1.0034 - accuracy: 0.6795 - val_loss: 2.3744 - val_accuracy: 0.3760\n",
      "Epoch 65/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.0688 - accuracy: 0.6455 - val_loss: 1.6452 - val_accuracy: 0.5132\n",
      "Epoch 66/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8398 - accuracy: 0.7265 - val_loss: 1.4561 - val_accuracy: 0.5592\n",
      "Epoch 67/68\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.7389 - accuracy: 0.7589 - val_loss: 1.5108 - val_accuracy: 0.5764\n",
      "Epoch 68/68\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.5769 - accuracy: 0.8171 - val_loss: 2.4248 - val_accuracy: 0.5262\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 2.6447 - accuracy: 0.5146\n",
      "Epoch 1/60\n",
      "125/125 [==============================] - 11s 49ms/step - loss: 2.7505 - accuracy: 0.2318 - val_loss: 2.6704 - val_accuracy: 0.1034\n",
      "Epoch 2/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.8005 - accuracy: 0.3903 - val_loss: 2.5314 - val_accuracy: 0.1050\n",
      "Epoch 3/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.5931 - accuracy: 0.4631 - val_loss: 226.4599 - val_accuracy: 0.1284\n",
      "Epoch 4/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.9605 - accuracy: 0.3086 - val_loss: 2.9328 - val_accuracy: 0.1692\n",
      "Epoch 5/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.8020 - accuracy: 0.3959 - val_loss: 1.8233 - val_accuracy: 0.4000\n",
      "Epoch 6/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.5039 - accuracy: 0.4925 - val_loss: 1.6463 - val_accuracy: 0.4114\n",
      "Epoch 7/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.2618 - accuracy: 0.5753 - val_loss: 1.5173 - val_accuracy: 0.4708\n",
      "Epoch 8/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.3441 - accuracy: 0.5623 - val_loss: 2.0601 - val_accuracy: 0.4580\n",
      "Epoch 9/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.2486 - accuracy: 0.5794 - val_loss: 2.3094 - val_accuracy: 0.3778\n",
      "Epoch 10/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1429 - accuracy: 0.6169 - val_loss: 2.5318 - val_accuracy: 0.4124\n",
      "Epoch 11/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.0133 - accuracy: 0.6640 - val_loss: 4.1599 - val_accuracy: 0.4162\n",
      "Epoch 12/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.9816 - accuracy: 0.6928 - val_loss: 2.1344 - val_accuracy: 0.3796\n",
      "Epoch 13/60\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 1.2328 - accuracy: 0.6131 - val_loss: 12.5031 - val_accuracy: 0.1044\n",
      "Epoch 14/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 2.1077 - accuracy: 0.3588 - val_loss: 65644.3047 - val_accuracy: 0.0954\n",
      "Epoch 15/60\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.8363 - accuracy: 0.3789 - val_loss: 1.9195 - val_accuracy: 0.4014\n",
      "Epoch 16/60\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.6419 - accuracy: 0.4452 - val_loss: 1.8405 - val_accuracy: 0.3820\n",
      "Epoch 17/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.6898 - accuracy: 0.4376 - val_loss: 1.9312 - val_accuracy: 0.4018\n",
      "Epoch 18/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.6003 - accuracy: 0.4632 - val_loss: 2.5406 - val_accuracy: 0.2456\n",
      "Epoch 19/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.6890 - accuracy: 0.4440 - val_loss: 2.4389 - val_accuracy: 0.2820\n",
      "Epoch 20/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.5512 - accuracy: 0.4960 - val_loss: 1.7612 - val_accuracy: 0.4154\n",
      "Epoch 21/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.4296 - accuracy: 0.5279 - val_loss: 18.7264 - val_accuracy: 0.3538\n",
      "Epoch 22/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.4595 - accuracy: 0.5106 - val_loss: 3.7679 - val_accuracy: 0.4184\n",
      "Epoch 23/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.2340 - accuracy: 0.5829 - val_loss: 1.4274 - val_accuracy: 0.5310\n",
      "Epoch 24/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.2457 - accuracy: 0.5817 - val_loss: 5.5386 - val_accuracy: 0.2040\n",
      "Epoch 25/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.4266 - accuracy: 0.5083 - val_loss: 2.0673 - val_accuracy: 0.4254\n",
      "Epoch 26/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.2917 - accuracy: 0.5631 - val_loss: 2.9803 - val_accuracy: 0.2560\n",
      "Epoch 27/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.6145 - accuracy: 0.4672 - val_loss: 1.6462 - val_accuracy: 0.4490\n",
      "Epoch 28/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.3956 - accuracy: 0.5493 - val_loss: 1.8612 - val_accuracy: 0.3832\n",
      "Epoch 29/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.4985 - accuracy: 0.5284 - val_loss: 2.1414 - val_accuracy: 0.3024\n",
      "Epoch 30/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.6460 - accuracy: 0.4574 - val_loss: 6.3578 - val_accuracy: 0.1184\n",
      "Epoch 31/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.5872 - accuracy: 0.4691 - val_loss: 2.8165 - val_accuracy: 0.3056\n",
      "Epoch 32/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.5433 - accuracy: 0.4975 - val_loss: 60.7413 - val_accuracy: 0.3516\n",
      "Epoch 33/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.4098 - accuracy: 0.5211 - val_loss: 1.9256 - val_accuracy: 0.3568\n",
      "Epoch 34/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.4432 - accuracy: 0.5092 - val_loss: 1.5821 - val_accuracy: 0.4810\n",
      "Epoch 35/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.3435 - accuracy: 0.5567 - val_loss: 515.6927 - val_accuracy: 0.2228\n",
      "Epoch 36/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.3451 - accuracy: 0.5692 - val_loss: 3.4902 - val_accuracy: 0.5000\n",
      "Epoch 37/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1250 - accuracy: 0.6258 - val_loss: 1.4341 - val_accuracy: 0.5054\n",
      "Epoch 38/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1344 - accuracy: 0.6291 - val_loss: 1.6511 - val_accuracy: 0.4648\n",
      "Epoch 39/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1488 - accuracy: 0.6120 - val_loss: 1.6300 - val_accuracy: 0.5318\n",
      "Epoch 40/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.9214 - accuracy: 0.6936 - val_loss: 3.8227 - val_accuracy: 0.4216\n",
      "Epoch 41/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.9133 - accuracy: 0.7140 - val_loss: 1.4426 - val_accuracy: 0.5400\n",
      "Epoch 42/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.7433 - accuracy: 0.7687 - val_loss: 1.3778 - val_accuracy: 0.5516\n",
      "Epoch 43/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.6046 - accuracy: 0.8060 - val_loss: 1.6800 - val_accuracy: 0.5396\n",
      "Epoch 44/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.5454 - accuracy: 0.8238 - val_loss: 2.0364 - val_accuracy: 0.5362\n",
      "Epoch 45/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4980 - accuracy: 0.8441 - val_loss: 1.8667 - val_accuracy: 0.5440\n",
      "Epoch 46/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4759 - accuracy: 0.8553 - val_loss: 2.0911 - val_accuracy: 0.5078\n",
      "Epoch 47/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4816 - accuracy: 0.8398 - val_loss: 2.7937 - val_accuracy: 0.5144\n",
      "Epoch 48/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4222 - accuracy: 0.8702 - val_loss: 2.5663 - val_accuracy: 0.5146\n",
      "Epoch 49/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4347 - accuracy: 0.8753 - val_loss: 3.4341 - val_accuracy: 0.5140\n",
      "Epoch 50/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4116 - accuracy: 0.8725 - val_loss: 2.0156 - val_accuracy: 0.5746\n",
      "Epoch 51/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2418 - accuracy: 0.9324 - val_loss: 2.7975 - val_accuracy: 0.4838\n",
      "Epoch 52/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.5313 - accuracy: 0.8425 - val_loss: 505.4796 - val_accuracy: 0.1184\n",
      "Epoch 53/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.2679 - accuracy: 0.5991 - val_loss: 17.9445 - val_accuracy: 0.4232\n",
      "Epoch 54/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.0158 - accuracy: 0.6757 - val_loss: 2.0002 - val_accuracy: 0.5254\n",
      "Epoch 55/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1043 - accuracy: 0.6519 - val_loss: 1.5990 - val_accuracy: 0.4738\n",
      "Epoch 56/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.9038 - accuracy: 0.7207 - val_loss: 496.8560 - val_accuracy: 0.1130\n",
      "Epoch 57/60\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.3310 - accuracy: 0.5535 - val_loss: 1.3176 - val_accuracy: 0.5552\n",
      "Epoch 58/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.7181 - accuracy: 0.7544 - val_loss: 1.3802 - val_accuracy: 0.5532\n",
      "Epoch 59/60\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4536 - accuracy: 0.8597 - val_loss: 2.3628 - val_accuracy: 0.4778\n",
      "Epoch 60/60\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.3252 - accuracy: 0.9083 - val_loss: 2.2132 - val_accuracy: 0.5486\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 2.2772 - accuracy: 0.5344\n",
      "Epoch 1/53\n",
      "141/141 [==============================] - 12s 50ms/step - loss: 2.6761 - accuracy: 0.2375 - val_loss: 2.8657 - val_accuracy: 0.1034\n",
      "Epoch 2/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 1.7469 - accuracy: 0.4175 - val_loss: 2.5501 - val_accuracy: 0.1724\n",
      "Epoch 3/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 1.7663 - accuracy: 0.4125 - val_loss: 2.3953 - val_accuracy: 0.2090\n",
      "Epoch 4/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.6539 - accuracy: 0.4503 - val_loss: 40.6732 - val_accuracy: 0.1414\n",
      "Epoch 5/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.7315 - accuracy: 0.4343 - val_loss: 10310.2891 - val_accuracy: 0.1066\n",
      "Epoch 6/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 1.8042 - accuracy: 0.3976 - val_loss: 2.1209 - val_accuracy: 0.3406\n",
      "Epoch 7/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.4918 - accuracy: 0.4947 - val_loss: 1.5755 - val_accuracy: 0.4504\n",
      "Epoch 8/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.3788 - accuracy: 0.5595 - val_loss: 15.0630 - val_accuracy: 0.3220\n",
      "Epoch 9/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 1.2788 - accuracy: 0.5853 - val_loss: 2.0489 - val_accuracy: 0.4236\n",
      "Epoch 10/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.0516 - accuracy: 0.6536 - val_loss: 1.7237 - val_accuracy: 0.4790\n",
      "Epoch 11/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.0872 - accuracy: 0.6525 - val_loss: 4.4281 - val_accuracy: 0.1840\n",
      "Epoch 12/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.2193 - accuracy: 0.5925 - val_loss: 1.5776 - val_accuracy: 0.4856\n",
      "Epoch 13/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.9491 - accuracy: 0.6931 - val_loss: 1.6052 - val_accuracy: 0.5038\n",
      "Epoch 14/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.7728 - accuracy: 0.7494 - val_loss: 1.7696 - val_accuracy: 0.4998\n",
      "Epoch 15/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 0.7968 - accuracy: 0.7577 - val_loss: 2.0461 - val_accuracy: 0.4816\n",
      "Epoch 16/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 0.9536 - accuracy: 0.7143 - val_loss: 1.9111 - val_accuracy: 0.4810\n",
      "Epoch 17/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.8038 - accuracy: 0.7448 - val_loss: 4.0299 - val_accuracy: 0.4606\n",
      "Epoch 18/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.6467 - accuracy: 0.7879 - val_loss: 1.8528 - val_accuracy: 0.5160\n",
      "Epoch 19/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.4929 - accuracy: 0.8512 - val_loss: 1.9206 - val_accuracy: 0.5272\n",
      "Epoch 20/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.4720 - accuracy: 0.8636 - val_loss: 27.0693 - val_accuracy: 0.3592\n",
      "Epoch 21/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.4549 - accuracy: 0.8571 - val_loss: 3.7263 - val_accuracy: 0.3758\n",
      "Epoch 22/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.6350 - accuracy: 0.8134 - val_loss: 11.6955 - val_accuracy: 0.4984\n",
      "Epoch 23/53\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.5380 - accuracy: 0.8506 - val_loss: 5.9465 - val_accuracy: 0.5372\n",
      "Epoch 24/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.4939 - accuracy: 0.8580 - val_loss: 3.4295 - val_accuracy: 0.5028\n",
      "Epoch 25/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 0.6591 - accuracy: 0.8092 - val_loss: 1.9565 - val_accuracy: 0.5156\n",
      "Epoch 26/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.3065 - accuracy: 0.9089 - val_loss: 2.1412 - val_accuracy: 0.5304\n",
      "Epoch 27/53\n",
      "141/141 [==============================] - 6s 41ms/step - loss: 0.2643 - accuracy: 0.9194 - val_loss: 2.3624 - val_accuracy: 0.5532\n",
      "Epoch 28/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.4734 - accuracy: 0.8601 - val_loss: 1.9933 - val_accuracy: 0.5588\n",
      "Epoch 29/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.2863 - accuracy: 0.9196 - val_loss: 2.2384 - val_accuracy: 0.5480\n",
      "Epoch 30/53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 6s 43ms/step - loss: 0.2225 - accuracy: 0.9390 - val_loss: 2.7829 - val_accuracy: 0.4524\n",
      "Epoch 31/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.4715 - accuracy: 0.8722 - val_loss: 2.4568 - val_accuracy: 0.4600\n",
      "Epoch 32/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.2899 - accuracy: 0.9045 - val_loss: 2.2222 - val_accuracy: 0.5664\n",
      "Epoch 33/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.2744 - accuracy: 0.9232 - val_loss: 4.8203 - val_accuracy: 0.2450\n",
      "Epoch 34/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.9395 - accuracy: 0.7220 - val_loss: 38.3500 - val_accuracy: 0.1550\n",
      "Epoch 35/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.7330 - accuracy: 0.8110 - val_loss: 2.0077 - val_accuracy: 0.5522\n",
      "Epoch 36/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.6407 - accuracy: 0.8256 - val_loss: 65.3412 - val_accuracy: 0.4934\n",
      "Epoch 37/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.8346 - accuracy: 0.7842 - val_loss: 11.7392 - val_accuracy: 0.3180\n",
      "Epoch 38/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 1.4959 - accuracy: 0.5372 - val_loss: 2.3681 - val_accuracy: 0.5136\n",
      "Epoch 39/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.0316 - accuracy: 0.6767 - val_loss: 1.4676 - val_accuracy: 0.5232\n",
      "Epoch 40/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.6758 - accuracy: 0.7828 - val_loss: 1.4268 - val_accuracy: 0.5816\n",
      "Epoch 41/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.4959 - accuracy: 0.8532 - val_loss: 1.6113 - val_accuracy: 0.5814\n",
      "Epoch 42/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.7068 - accuracy: 0.7863 - val_loss: 9.3283 - val_accuracy: 0.1322\n",
      "Epoch 43/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 1.0389 - accuracy: 0.6575 - val_loss: 1.6802 - val_accuracy: 0.5400\n",
      "Epoch 44/53\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.5330 - accuracy: 0.8285 - val_loss: 1.5881 - val_accuracy: 0.5830\n",
      "Epoch 45/53\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.3302 - accuracy: 0.9020 - val_loss: 1.8635 - val_accuracy: 0.5594\n",
      "Epoch 46/53\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.2389 - accuracy: 0.9205 - val_loss: 1.9898 - val_accuracy: 0.5980\n",
      "Epoch 47/53\n",
      "141/141 [==============================] - 6s 46ms/step - loss: 0.1310 - accuracy: 0.9551 - val_loss: 2.1179 - val_accuracy: 0.6050\n",
      "Epoch 48/53\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0892 - accuracy: 0.9692 - val_loss: 2.2870 - val_accuracy: 0.6008\n",
      "Epoch 49/53\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 2.3151 - val_accuracy: 0.6104\n",
      "Epoch 50/53\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0727 - accuracy: 0.9760 - val_loss: 2.4135 - val_accuracy: 0.6158\n",
      "Epoch 51/53\n",
      "141/141 [==============================] - 6s 45ms/step - loss: 0.0687 - accuracy: 0.9761 - val_loss: 2.5821 - val_accuracy: 0.6072\n",
      "Epoch 52/53\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0602 - accuracy: 0.9798 - val_loss: 2.3636 - val_accuracy: 0.6122\n",
      "Epoch 53/53\n",
      "141/141 [==============================] - 6s 44ms/step - loss: 0.0579 - accuracy: 0.9794 - val_loss: 2.4197 - val_accuracy: 0.6118\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 2.5236 - accuracy: 0.6110\n",
      "Epoch 1/48\n",
      "157/157 [==============================] - 14s 55ms/step - loss: 2.6593 - accuracy: 0.2304 - val_loss: 2.6582 - val_accuracy: 0.1092\n",
      "Epoch 2/48\n",
      "157/157 [==============================] - 7s 45ms/step - loss: 1.7887 - accuracy: 0.3951 - val_loss: 2.6555 - val_accuracy: 0.1162\n",
      "Epoch 3/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.7118 - accuracy: 0.4220 - val_loss: 2.9657 - val_accuracy: 0.3302\n",
      "Epoch 4/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.5463 - accuracy: 0.4736 - val_loss: 3.3191 - val_accuracy: 0.3774\n",
      "Epoch 5/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 1.4298 - accuracy: 0.5099 - val_loss: 10.6449 - val_accuracy: 0.1584\n",
      "Epoch 6/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.5357 - accuracy: 0.4951 - val_loss: 479.9524 - val_accuracy: 0.1098\n",
      "Epoch 7/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.6106 - accuracy: 0.4647 - val_loss: 28.3046 - val_accuracy: 0.1426\n",
      "Epoch 8/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.3798 - accuracy: 0.5234 - val_loss: 1.5637 - val_accuracy: 0.4838\n",
      "Epoch 9/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.1805 - accuracy: 0.6047 - val_loss: 1.5527 - val_accuracy: 0.4878\n",
      "Epoch 10/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.0935 - accuracy: 0.6485 - val_loss: 8.6309 - val_accuracy: 0.4676\n",
      "Epoch 11/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.0790 - accuracy: 0.6403 - val_loss: 1.7351 - val_accuracy: 0.4588\n",
      "Epoch 12/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9245 - accuracy: 0.6892 - val_loss: 1.6941 - val_accuracy: 0.5084\n",
      "Epoch 13/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9292 - accuracy: 0.6987 - val_loss: 14.4323 - val_accuracy: 0.2472\n",
      "Epoch 14/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.3519 - accuracy: 0.5409 - val_loss: 1.3988 - val_accuracy: 0.5088\n",
      "Epoch 15/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 1.3969 - accuracy: 0.5613 - val_loss: 1.9144 - val_accuracy: 0.3764\n",
      "Epoch 16/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.1063 - accuracy: 0.6403 - val_loss: 1.6375 - val_accuracy: 0.5066\n",
      "Epoch 17/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9726 - accuracy: 0.6685 - val_loss: 1.9551 - val_accuracy: 0.3618\n",
      "Epoch 18/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 1.1734 - accuracy: 0.6191 - val_loss: 1.5408 - val_accuracy: 0.5292\n",
      "Epoch 19/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9360 - accuracy: 0.6920 - val_loss: 2.2834 - val_accuracy: 0.3452\n",
      "Epoch 20/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.4013 - accuracy: 0.5685 - val_loss: 1.7932 - val_accuracy: 0.4742\n",
      "Epoch 21/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.9301 - accuracy: 0.6885 - val_loss: 1.3476 - val_accuracy: 0.5572\n",
      "Epoch 22/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.7272 - accuracy: 0.7654 - val_loss: 1.8485 - val_accuracy: 0.4340\n",
      "Epoch 23/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.6448 - accuracy: 0.7793 - val_loss: 16.7188 - val_accuracy: 0.1970\n",
      "Epoch 24/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 1.0164 - accuracy: 0.6768 - val_loss: 3.6622 - val_accuracy: 0.4258\n",
      "Epoch 25/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.8629 - accuracy: 0.7208 - val_loss: 2.2083 - val_accuracy: 0.3836\n",
      "Epoch 26/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9745 - accuracy: 0.6776 - val_loss: 3.1375 - val_accuracy: 0.1236\n",
      "Epoch 27/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 1.2674 - accuracy: 0.5911 - val_loss: 2.1077 - val_accuracy: 0.4716\n",
      "Epoch 28/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9505 - accuracy: 0.7012 - val_loss: 1.9058 - val_accuracy: 0.4160\n",
      "Epoch 29/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.7785 - accuracy: 0.7457 - val_loss: 2.5176 - val_accuracy: 0.3408\n",
      "Epoch 30/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.9242 - accuracy: 0.7051 - val_loss: 1.7520 - val_accuracy: 0.5122\n",
      "Epoch 31/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.4763 - accuracy: 0.8354 - val_loss: 1.9209 - val_accuracy: 0.5472\n",
      "Epoch 32/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.3075 - accuracy: 0.8973 - val_loss: 2.0201 - val_accuracy: 0.5658\n",
      "Epoch 33/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.2527 - accuracy: 0.9123 - val_loss: 1.9319 - val_accuracy: 0.5850\n",
      "Epoch 34/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.2063 - accuracy: 0.9267 - val_loss: 1.9193 - val_accuracy: 0.6084\n",
      "Epoch 35/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.1709 - accuracy: 0.9398 - val_loss: 2.6708 - val_accuracy: 0.5342\n",
      "Epoch 36/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.1529 - accuracy: 0.9483 - val_loss: 2.1238 - val_accuracy: 0.6070\n",
      "Epoch 37/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.1267 - accuracy: 0.9552 - val_loss: 2.3229 - val_accuracy: 0.5598\n",
      "Epoch 38/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.1259 - accuracy: 0.9568 - val_loss: 2.4641 - val_accuracy: 0.5732\n",
      "Epoch 39/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.1137 - accuracy: 0.9593 - val_loss: 2.1983 - val_accuracy: 0.5946\n",
      "Epoch 40/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.1289 - accuracy: 0.9561 - val_loss: 2.2695 - val_accuracy: 0.5616\n",
      "Epoch 41/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.0799 - accuracy: 0.9716 - val_loss: 2.3198 - val_accuracy: 0.5702\n",
      "Epoch 42/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0969 - accuracy: 0.9680 - val_loss: 2.2419 - val_accuracy: 0.6022\n",
      "Epoch 43/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0968 - accuracy: 0.9669 - val_loss: 1.9308 - val_accuracy: 0.6486\n",
      "Epoch 44/48\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.0739 - accuracy: 0.9726 - val_loss: 2.3017 - val_accuracy: 0.5856\n",
      "Epoch 45/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.0778 - accuracy: 0.9728 - val_loss: 2.5465 - val_accuracy: 0.5782\n",
      "Epoch 46/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.0991 - accuracy: 0.9644 - val_loss: 2.2947 - val_accuracy: 0.5804\n",
      "Epoch 47/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.0864 - accuracy: 0.9699 - val_loss: 2.1650 - val_accuracy: 0.6004\n",
      "Epoch 48/48\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.0741 - accuracy: 0.9748 - val_loss: 1.9855 - val_accuracy: 0.6318\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 2.0435 - accuracy: 0.6180\n",
      "Epoch 1/43\n",
      "172/172 [==============================] - 15s 52ms/step - loss: 2.6494 - accuracy: 0.2384 - val_loss: 2.4852 - val_accuracy: 0.1082\n",
      "Epoch 2/43\n",
      "172/172 [==============================] - 8s 44ms/step - loss: 1.7015 - accuracy: 0.4096 - val_loss: 2.3053 - val_accuracy: 0.2464\n",
      "Epoch 3/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4979 - accuracy: 0.4919 - val_loss: 1.7890 - val_accuracy: 0.4044\n",
      "Epoch 4/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.3740 - accuracy: 0.5455 - val_loss: 1.5754 - val_accuracy: 0.4354\n",
      "Epoch 5/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.7758 - accuracy: 0.4091 - val_loss: 117.0854 - val_accuracy: 0.2318\n",
      "Epoch 6/43\n",
      "172/172 [==============================] - 7s 44ms/step - loss: 1.6758 - accuracy: 0.4513 - val_loss: 200.2114 - val_accuracy: 0.2620\n",
      "Epoch 7/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4928 - accuracy: 0.4954 - val_loss: 1.6505 - val_accuracy: 0.4716\n",
      "Epoch 8/43\n",
      "172/172 [==============================] - 7s 44ms/step - loss: 1.3365 - accuracy: 0.5518 - val_loss: 162.8228 - val_accuracy: 0.2054\n",
      "Epoch 9/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4679 - accuracy: 0.5218 - val_loss: 7.8822 - val_accuracy: 0.1320\n",
      "Epoch 10/43\n",
      "172/172 [==============================] - 8s 44ms/step - loss: 1.7144 - accuracy: 0.4777 - val_loss: 38.6571 - val_accuracy: 0.2372\n",
      "Epoch 11/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.5198 - accuracy: 0.5039 - val_loss: 1.5928 - val_accuracy: 0.4678\n",
      "Epoch 12/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4133 - accuracy: 0.5442 - val_loss: 7.2301 - val_accuracy: 0.1454\n",
      "Epoch 13/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.3397 - accuracy: 0.5575 - val_loss: 1.2887 - val_accuracy: 0.5460\n",
      "Epoch 14/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.1325 - accuracy: 0.6227 - val_loss: 1.2260 - val_accuracy: 0.5612\n",
      "Epoch 15/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.1237 - accuracy: 0.6292 - val_loss: 18.1421 - val_accuracy: 0.4236\n",
      "Epoch 16/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.1402 - accuracy: 0.6155 - val_loss: 1.3415 - val_accuracy: 0.5646\n",
      "Epoch 17/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 0.9342 - accuracy: 0.6987 - val_loss: 1.2819 - val_accuracy: 0.5634\n",
      "Epoch 18/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.0768 - accuracy: 0.6462 - val_loss: 1428.9753 - val_accuracy: 0.1048\n",
      "Epoch 19/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.8670 - accuracy: 0.3751 - val_loss: 1.7963 - val_accuracy: 0.3618\n",
      "Epoch 20/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.6805 - accuracy: 0.4433 - val_loss: 10.6270 - val_accuracy: 0.2754\n",
      "Epoch 21/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.5273 - accuracy: 0.4936 - val_loss: 1.4167 - val_accuracy: 0.4966\n",
      "Epoch 22/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.5056 - accuracy: 0.5008 - val_loss: 7.0224 - val_accuracy: 0.3212\n",
      "Epoch 23/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.6539 - accuracy: 0.4609 - val_loss: 16.8536 - val_accuracy: 0.2658\n",
      "Epoch 24/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.6056 - accuracy: 0.4512 - val_loss: 1.5136 - val_accuracy: 0.4650\n",
      "Epoch 25/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4240 - accuracy: 0.5193 - val_loss: 1.4273 - val_accuracy: 0.4790\n",
      "Epoch 26/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.6522 - accuracy: 0.4544 - val_loss: 2.4795 - val_accuracy: 0.3726\n",
      "Epoch 27/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4979 - accuracy: 0.4903 - val_loss: 3.2325 - val_accuracy: 0.1352\n",
      "Epoch 28/43\n",
      "172/172 [==============================] - 7s 42ms/step - loss: 1.6787 - accuracy: 0.4267 - val_loss: 1.6823 - val_accuracy: 0.4072\n",
      "Epoch 29/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4879 - accuracy: 0.5014 - val_loss: 1.6213 - val_accuracy: 0.4642\n",
      "Epoch 30/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.3534 - accuracy: 0.5386 - val_loss: 1.6282 - val_accuracy: 0.5014\n",
      "Epoch 31/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.2270 - accuracy: 0.5885 - val_loss: 1.6265 - val_accuracy: 0.5010\n",
      "Epoch 32/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.2676 - accuracy: 0.5818 - val_loss: 1.9970 - val_accuracy: 0.2852\n",
      "Epoch 33/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.4145 - accuracy: 0.5196 - val_loss: 1.5926 - val_accuracy: 0.4552\n",
      "Epoch 34/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.3039 - accuracy: 0.5660 - val_loss: 1.4636 - val_accuracy: 0.5054\n",
      "Epoch 35/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.5143 - accuracy: 0.5111 - val_loss: 2.8740 - val_accuracy: 0.2180\n",
      "Epoch 36/43\n",
      "172/172 [==============================] - 7s 42ms/step - loss: 1.6666 - accuracy: 0.4521 - val_loss: 2.3495 - val_accuracy: 0.2980\n",
      "Epoch 37/43\n",
      "172/172 [==============================] - 7s 42ms/step - loss: 1.4029 - accuracy: 0.5275 - val_loss: 1.9536 - val_accuracy: 0.4356\n",
      "Epoch 38/43\n",
      "172/172 [==============================] - 7s 42ms/step - loss: 1.4458 - accuracy: 0.5283 - val_loss: 1.6582 - val_accuracy: 0.4152\n",
      "Epoch 39/43\n",
      "172/172 [==============================] - 7s 42ms/step - loss: 1.4921 - accuracy: 0.5025 - val_loss: 1.9399 - val_accuracy: 0.3946\n",
      "Epoch 40/43\n",
      "172/172 [==============================] - 7s 41ms/step - loss: 1.2556 - accuracy: 0.5878 - val_loss: 1.5273 - val_accuracy: 0.4876\n",
      "Epoch 41/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 7s 41ms/step - loss: 1.1936 - accuracy: 0.6099 - val_loss: 1.8148 - val_accuracy: 0.5414\n",
      "Epoch 42/43\n",
      "172/172 [==============================] - 8s 45ms/step - loss: 1.0813 - accuracy: 0.6409 - val_loss: 1.8231 - val_accuracy: 0.5154\n",
      "Epoch 43/43\n",
      "172/172 [==============================] - 7s 43ms/step - loss: 1.0281 - accuracy: 0.6505 - val_loss: 1.3426 - val_accuracy: 0.5586\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 1.3845 - accuracy: 0.5530\n",
      "Epoch 1/40\n",
      "188/188 [==============================] - 14s 46ms/step - loss: 2.6773 - accuracy: 0.2480 - val_loss: 3.0846 - val_accuracy: 0.0986\n",
      "Epoch 2/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.6166 - accuracy: 0.4339 - val_loss: 2.9498 - val_accuracy: 0.2288\n",
      "Epoch 3/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.5000 - accuracy: 0.4906 - val_loss: 6.3394 - val_accuracy: 0.3812\n",
      "Epoch 4/40\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 1.6507 - accuracy: 0.4570 - val_loss: 4.4869 - val_accuracy: 0.3336\n",
      "Epoch 5/40\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 1.5090 - accuracy: 0.4803 - val_loss: 1.4878 - val_accuracy: 0.4522\n",
      "Epoch 6/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.3901 - accuracy: 0.5337 - val_loss: 2.0016 - val_accuracy: 0.3628\n",
      "Epoch 7/40\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 1.6280 - accuracy: 0.4829 - val_loss: 2.2891 - val_accuracy: 0.3492\n",
      "Epoch 8/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.3834 - accuracy: 0.5300 - val_loss: 50.0774 - val_accuracy: 0.1378\n",
      "Epoch 9/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.4421 - accuracy: 0.5081 - val_loss: 1.5857 - val_accuracy: 0.4658\n",
      "Epoch 10/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.2173 - accuracy: 0.5914 - val_loss: 1.5376 - val_accuracy: 0.4714\n",
      "Epoch 11/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.1606 - accuracy: 0.6238 - val_loss: 2.1713 - val_accuracy: 0.3638\n",
      "Epoch 12/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.2726 - accuracy: 0.5834 - val_loss: 2.0933 - val_accuracy: 0.3054\n",
      "Epoch 13/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.4790 - accuracy: 0.5166 - val_loss: 3.9279 - val_accuracy: 0.2140\n",
      "Epoch 14/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 1.3235 - accuracy: 0.5658 - val_loss: 1.5145 - val_accuracy: 0.4896\n",
      "Epoch 15/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 1.1198 - accuracy: 0.6366 - val_loss: 1.2401 - val_accuracy: 0.5616\n",
      "Epoch 16/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.0891 - accuracy: 0.6469 - val_loss: 1.5088 - val_accuracy: 0.4954\n",
      "Epoch 17/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 1.0236 - accuracy: 0.6660 - val_loss: 1.6523 - val_accuracy: 0.4980\n",
      "Epoch 18/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 1.0787 - accuracy: 0.6741 - val_loss: 470.8521 - val_accuracy: 0.1470\n",
      "Epoch 19/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.3631 - accuracy: 0.5524 - val_loss: 18.2914 - val_accuracy: 0.1434\n",
      "Epoch 20/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.5304 - accuracy: 0.5118 - val_loss: 60.8857 - val_accuracy: 0.3810\n",
      "Epoch 21/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.2479 - accuracy: 0.5933 - val_loss: 1.3825 - val_accuracy: 0.5516\n",
      "Epoch 22/40\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 1.0091 - accuracy: 0.6739 - val_loss: 1.2221 - val_accuracy: 0.6012\n",
      "Epoch 23/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.9295 - accuracy: 0.7141 - val_loss: 5.5304 - val_accuracy: 0.3182\n",
      "Epoch 24/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.9625 - accuracy: 0.7087 - val_loss: 1.4337 - val_accuracy: 0.6252\n",
      "Epoch 25/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.6993 - accuracy: 0.7805 - val_loss: 1.3043 - val_accuracy: 0.6070\n",
      "Epoch 26/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.6489 - accuracy: 0.8076 - val_loss: 1.8855 - val_accuracy: 0.5782\n",
      "Epoch 27/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.6659 - accuracy: 0.7976 - val_loss: 1.9333 - val_accuracy: 0.5232\n",
      "Epoch 28/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.7116 - accuracy: 0.7674 - val_loss: 1.9605 - val_accuracy: 0.5206\n",
      "Epoch 29/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.6459 - accuracy: 0.7866 - val_loss: 3.6278 - val_accuracy: 0.2046\n",
      "Epoch 30/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.5285 - accuracy: 0.4805 - val_loss: 9.2385 - val_accuracy: 0.3402\n",
      "Epoch 31/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.1307 - accuracy: 0.6280 - val_loss: 5.4522 - val_accuracy: 0.5294\n",
      "Epoch 32/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.8732 - accuracy: 0.7196 - val_loss: 1.2930 - val_accuracy: 0.6082\n",
      "Epoch 33/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.6804 - accuracy: 0.7967 - val_loss: 1.2390 - val_accuracy: 0.5968\n",
      "Epoch 34/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.5384 - accuracy: 0.8286 - val_loss: 1.5046 - val_accuracy: 0.6046\n",
      "Epoch 35/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.3719 - accuracy: 0.8739 - val_loss: 1.5467 - val_accuracy: 0.6224\n",
      "Epoch 36/40\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.3040 - accuracy: 0.8964 - val_loss: 1.6697 - val_accuracy: 0.6096\n",
      "Epoch 37/40\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.2654 - accuracy: 0.9067 - val_loss: 1.8318 - val_accuracy: 0.6084\n",
      "Epoch 38/40\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.6570 - accuracy: 0.7945 - val_loss: 1.6132 - val_accuracy: 0.5076\n",
      "Epoch 39/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.6910 - accuracy: 0.7702 - val_loss: 1.3835 - val_accuracy: 0.6066\n",
      "Epoch 40/40\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.3290 - accuracy: 0.8927 - val_loss: 1.5974 - val_accuracy: 0.6152\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 1.6507 - accuracy: 0.6086\n",
      "Epoch 1/36\n",
      "204/204 [==============================] - 14s 45ms/step - loss: 2.5192 - accuracy: 0.2664 - val_loss: 2.2970 - val_accuracy: 0.1154\n",
      "Epoch 2/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.7665 - accuracy: 0.3989 - val_loss: 3.1086 - val_accuracy: 0.2208\n",
      "Epoch 3/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.7296 - accuracy: 0.4290 - val_loss: 1.9069 - val_accuracy: 0.4342\n",
      "Epoch 4/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.3938 - accuracy: 0.5301 - val_loss: 1.3605 - val_accuracy: 0.5074\n",
      "Epoch 5/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.5436 - accuracy: 0.4855 - val_loss: 4.7810 - val_accuracy: 0.1044\n",
      "Epoch 6/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.9007 - accuracy: 0.3922 - val_loss: 3.5467 - val_accuracy: 0.2300\n",
      "Epoch 7/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.8086 - accuracy: 0.4059 - val_loss: 17.0992 - val_accuracy: 0.3824\n",
      "Epoch 8/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 1.7014 - accuracy: 0.4401 - val_loss: 1317.1768 - val_accuracy: 0.1324\n",
      "Epoch 9/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.6324 - accuracy: 0.4552 - val_loss: 3.9983 - val_accuracy: 0.1692\n",
      "Epoch 10/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.4886 - accuracy: 0.5073 - val_loss: 47.2259 - val_accuracy: 0.3306\n",
      "Epoch 11/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.5721 - accuracy: 0.4906 - val_loss: 1.7834 - val_accuracy: 0.4030\n",
      "Epoch 12/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.4400 - accuracy: 0.5231 - val_loss: 3.6226 - val_accuracy: 0.1466\n",
      "Epoch 13/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 2.1889 - accuracy: 0.3021 - val_loss: 1.9549 - val_accuracy: 0.2954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.5223 - accuracy: 0.4577 - val_loss: 1.7882 - val_accuracy: 0.4398\n",
      "Epoch 15/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 1.4738 - accuracy: 0.5031 - val_loss: 1.4525 - val_accuracy: 0.4824\n",
      "Epoch 16/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.3651 - accuracy: 0.5431 - val_loss: 431.8322 - val_accuracy: 0.2298\n",
      "Epoch 17/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.5297 - accuracy: 0.5136 - val_loss: 2.8472 - val_accuracy: 0.3950\n",
      "Epoch 18/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.3114 - accuracy: 0.5608 - val_loss: 1.3012 - val_accuracy: 0.5282\n",
      "Epoch 19/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.1912 - accuracy: 0.6098 - val_loss: 1.5328 - val_accuracy: 0.5478\n",
      "Epoch 20/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.0255 - accuracy: 0.6614 - val_loss: 6.5040 - val_accuracy: 0.3346\n",
      "Epoch 21/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 1.0128 - accuracy: 0.6611 - val_loss: 2.1821 - val_accuracy: 0.4298\n",
      "Epoch 22/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.2138 - accuracy: 0.6177 - val_loss: 21.1409 - val_accuracy: 0.3332\n",
      "Epoch 23/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.4539 - accuracy: 0.5310 - val_loss: 1.4382 - val_accuracy: 0.5028\n",
      "Epoch 24/36\n",
      "204/204 [==============================] - 8s 41ms/step - loss: 1.0609 - accuracy: 0.6488 - val_loss: 1.2719 - val_accuracy: 0.5562\n",
      "Epoch 25/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 0.9176 - accuracy: 0.6972 - val_loss: 2.4918 - val_accuracy: 0.2756\n",
      "Epoch 26/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 1.4628 - accuracy: 0.5183 - val_loss: 1.5018 - val_accuracy: 0.4938\n",
      "Epoch 27/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 1.2647 - accuracy: 0.5748 - val_loss: 10.2183 - val_accuracy: 0.5266\n",
      "Epoch 28/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.0943 - accuracy: 0.6448 - val_loss: 1.1627 - val_accuracy: 0.6146\n",
      "Epoch 29/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 0.9049 - accuracy: 0.7061 - val_loss: 1.1613 - val_accuracy: 0.6084\n",
      "Epoch 30/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.1754 - accuracy: 0.6173 - val_loss: 8.4245 - val_accuracy: 0.3164\n",
      "Epoch 31/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.2805 - accuracy: 0.5794 - val_loss: 1.2910 - val_accuracy: 0.5476\n",
      "Epoch 32/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.1125 - accuracy: 0.6488 - val_loss: 18.1312 - val_accuracy: 0.5478\n",
      "Epoch 33/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.1550 - accuracy: 0.6239 - val_loss: 1.2783 - val_accuracy: 0.5516\n",
      "Epoch 34/36\n",
      "204/204 [==============================] - 9s 42ms/step - loss: 1.0753 - accuracy: 0.6601 - val_loss: 1.3591 - val_accuracy: 0.5532\n",
      "Epoch 35/36\n",
      "204/204 [==============================] - 8s 42ms/step - loss: 0.9768 - accuracy: 0.6854 - val_loss: 8.1299 - val_accuracy: 0.5598\n",
      "Epoch 36/36\n",
      "204/204 [==============================] - 9s 43ms/step - loss: 0.7622 - accuracy: 0.7481 - val_loss: 1.1280 - val_accuracy: 0.6370\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 1.1298 - accuracy: 0.6408\n",
      "Epoch 1/34\n",
      "219/219 [==============================] - 16s 46ms/step - loss: 2.4960 - accuracy: 0.2648 - val_loss: 3.2916 - val_accuracy: 0.1048\n",
      "Epoch 2/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.6078 - accuracy: 0.4462 - val_loss: 2.0920 - val_accuracy: 0.3110\n",
      "Epoch 3/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.4380 - accuracy: 0.5148 - val_loss: 25.4735 - val_accuracy: 0.3658\n",
      "Epoch 4/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.3875 - accuracy: 0.5319 - val_loss: 667.1970 - val_accuracy: 0.1014\n",
      "Epoch 5/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.8063 - accuracy: 0.4231 - val_loss: 1.9187 - val_accuracy: 0.3502\n",
      "Epoch 6/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.7825 - accuracy: 0.4408 - val_loss: 3.0852 - val_accuracy: 0.1964\n",
      "Epoch 7/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.6226 - accuracy: 0.4596 - val_loss: 4.7306 - val_accuracy: 0.1132\n",
      "Epoch 8/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.5579 - accuracy: 0.4650 - val_loss: 2.1862 - val_accuracy: 0.4048\n",
      "Epoch 9/34\n",
      "219/219 [==============================] - 10s 44ms/step - loss: 1.4768 - accuracy: 0.5047 - val_loss: 1.9713 - val_accuracy: 0.3320\n",
      "Epoch 10/34\n",
      "219/219 [==============================] - 10s 44ms/step - loss: 1.7629 - accuracy: 0.4289 - val_loss: 2.2863 - val_accuracy: 0.2256\n",
      "Epoch 11/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.4685 - accuracy: 0.5101 - val_loss: 1.3734 - val_accuracy: 0.5038\n",
      "Epoch 12/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.2806 - accuracy: 0.5676 - val_loss: 1.5708 - val_accuracy: 0.4686\n",
      "Epoch 13/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.4077 - accuracy: 0.5496 - val_loss: 1.3128 - val_accuracy: 0.5274\n",
      "Epoch 14/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.4270 - accuracy: 0.5542 - val_loss: 7.1283 - val_accuracy: 0.3634\n",
      "Epoch 15/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.2468 - accuracy: 0.5909 - val_loss: 1.5087 - val_accuracy: 0.5114\n",
      "Epoch 16/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.1803 - accuracy: 0.6122 - val_loss: 2.6340 - val_accuracy: 0.2460\n",
      "Epoch 17/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.5615 - accuracy: 0.5240 - val_loss: 8.7168 - val_accuracy: 0.4780\n",
      "Epoch 18/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.3687 - accuracy: 0.5681 - val_loss: 2.2343 - val_accuracy: 0.2896\n",
      "Epoch 19/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.5275 - accuracy: 0.4968 - val_loss: 1.7986 - val_accuracy: 0.4024\n",
      "Epoch 20/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.3109 - accuracy: 0.5835 - val_loss: 2.1646 - val_accuracy: 0.2940\n",
      "Epoch 21/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.2874 - accuracy: 0.5744 - val_loss: 1.5406 - val_accuracy: 0.5120\n",
      "Epoch 22/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.3475 - accuracy: 0.5696 - val_loss: 1.2269 - val_accuracy: 0.5748\n",
      "Epoch 23/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.1307 - accuracy: 0.6271 - val_loss: 287.3535 - val_accuracy: 0.1478\n",
      "Epoch 24/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.4692 - accuracy: 0.5193 - val_loss: 1.6543 - val_accuracy: 0.4294\n",
      "Epoch 25/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 1.4181 - accuracy: 0.5376 - val_loss: 34.2684 - val_accuracy: 0.1146\n",
      "Epoch 26/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.3818 - accuracy: 0.5185 - val_loss: 1.3452 - val_accuracy: 0.5160\n",
      "Epoch 27/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 1.0623 - accuracy: 0.6313 - val_loss: 1.1182 - val_accuracy: 0.6084\n",
      "Epoch 28/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 0.9055 - accuracy: 0.6824 - val_loss: 1.1533 - val_accuracy: 0.6056\n",
      "Epoch 29/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 0.7990 - accuracy: 0.7225 - val_loss: 5.9570 - val_accuracy: 0.2940\n",
      "Epoch 30/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 0.8438 - accuracy: 0.7048 - val_loss: 1.1181 - val_accuracy: 0.6368\n",
      "Epoch 31/34\n",
      "219/219 [==============================] - 9s 42ms/step - loss: 0.6445 - accuracy: 0.7742 - val_loss: 1.2361 - val_accuracy: 0.6282\n",
      "Epoch 32/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 0.5167 - accuracy: 0.8212 - val_loss: 1.3797 - val_accuracy: 0.6162\n",
      "Epoch 33/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 0.4700 - accuracy: 0.8344 - val_loss: 1.6341 - val_accuracy: 0.5900\n",
      "Epoch 34/34\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 0.3600 - accuracy: 0.8766 - val_loss: 1.9631 - val_accuracy: 0.5936\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 2.0896 - accuracy: 0.5930\n",
      "Epoch 1/32\n",
      "235/235 [==============================] - 16s 45ms/step - loss: 2.5354 - accuracy: 0.2576 - val_loss: 2.8730 - val_accuracy: 0.1050\n",
      "Epoch 2/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.6429 - accuracy: 0.4294 - val_loss: 1.8645 - val_accuracy: 0.3540\n",
      "Epoch 3/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.5340 - accuracy: 0.4992 - val_loss: 1.4779 - val_accuracy: 0.4632\n",
      "Epoch 4/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.4258 - accuracy: 0.5328 - val_loss: 1.7321 - val_accuracy: 0.3804\n",
      "Epoch 5/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 1.6153 - accuracy: 0.4843 - val_loss: 11.4049 - val_accuracy: 0.2844\n",
      "Epoch 6/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.3985 - accuracy: 0.5393 - val_loss: 1.6648 - val_accuracy: 0.5060\n",
      "Epoch 7/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 1.5195 - accuracy: 0.5193 - val_loss: 1.8369 - val_accuracy: 0.3518\n",
      "Epoch 8/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.5427 - accuracy: 0.4779 - val_loss: 2.0192 - val_accuracy: 0.3458\n",
      "Epoch 9/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.4586 - accuracy: 0.5123 - val_loss: 11.0226 - val_accuracy: 0.1152\n",
      "Epoch 10/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 1.4287 - accuracy: 0.5352 - val_loss: 1.3386 - val_accuracy: 0.5122\n",
      "Epoch 11/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.2670 - accuracy: 0.5964 - val_loss: 47.4608 - val_accuracy: 0.1020\n",
      "Epoch 12/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 2.0716 - accuracy: 0.3515 - val_loss: 2.9181 - val_accuracy: 0.2872\n",
      "Epoch 13/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 1.7341 - accuracy: 0.3990 - val_loss: 1.7330 - val_accuracy: 0.3704\n",
      "Epoch 14/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.6166 - accuracy: 0.4417 - val_loss: 3.0665 - val_accuracy: 0.2104\n",
      "Epoch 15/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.6098 - accuracy: 0.4496 - val_loss: 2.0871 - val_accuracy: 0.2988\n",
      "Epoch 16/32\n",
      "235/235 [==============================] - 10s 41ms/step - loss: 1.9283 - accuracy: 0.3710 - val_loss: 1.9722 - val_accuracy: 0.3250\n",
      "Epoch 17/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.7330 - accuracy: 0.4232 - val_loss: 2.4900 - val_accuracy: 0.2424\n",
      "Epoch 18/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.7753 - accuracy: 0.3865 - val_loss: 1.9845 - val_accuracy: 0.3196\n",
      "Epoch 19/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.8007 - accuracy: 0.3923 - val_loss: 1.6732 - val_accuracy: 0.4184\n",
      "Epoch 20/32\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 1.5322 - accuracy: 0.4674 - val_loss: 1.4722 - val_accuracy: 0.4658\n",
      "Epoch 21/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.4819 - accuracy: 0.4888 - val_loss: 2.9302 - val_accuracy: 0.1922\n",
      "Epoch 22/32\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 1.6168 - accuracy: 0.4549 - val_loss: 2.2481 - val_accuracy: 0.3738\n",
      "Epoch 23/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.4059 - accuracy: 0.5085 - val_loss: 1.5799 - val_accuracy: 0.4868\n",
      "Epoch 24/32\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 1.2602 - accuracy: 0.5571 - val_loss: 1.4702 - val_accuracy: 0.4842\n",
      "Epoch 25/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.3258 - accuracy: 0.5483 - val_loss: 4.0535 - val_accuracy: 0.2158\n",
      "Epoch 26/32\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 1.2437 - accuracy: 0.5766 - val_loss: 2.3263 - val_accuracy: 0.4982\n",
      "Epoch 27/32\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 1.0843 - accuracy: 0.6168 - val_loss: 1.2042 - val_accuracy: 0.5686\n",
      "Epoch 28/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.0369 - accuracy: 0.6395 - val_loss: 1.6937 - val_accuracy: 0.4174\n",
      "Epoch 29/32\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 1.1895 - accuracy: 0.5913 - val_loss: 1.2422 - val_accuracy: 0.5488\n",
      "Epoch 30/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.0638 - accuracy: 0.6285 - val_loss: 1.5277 - val_accuracy: 0.4886\n",
      "Epoch 31/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 1.0120 - accuracy: 0.6550 - val_loss: 1.3079 - val_accuracy: 0.5444\n",
      "Epoch 32/32\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 0.8138 - accuracy: 0.7167 - val_loss: 1.7414 - val_accuracy: 0.5084\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 1.6094 - accuracy: 0.5068\n",
      "Epoch 1/30\n",
      "250/250 [==============================] - 16s 44ms/step - loss: 2.3831 - accuracy: 0.2696 - val_loss: 3.1152 - val_accuracy: 0.1182\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.6324 - accuracy: 0.4442 - val_loss: 1.6246 - val_accuracy: 0.4190\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.6075 - accuracy: 0.4529 - val_loss: 2.5113 - val_accuracy: 0.2480\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.6290 - accuracy: 0.4548 - val_loss: 12.1625 - val_accuracy: 0.3542\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.4866 - accuracy: 0.4965 - val_loss: 1.8081 - val_accuracy: 0.3876\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.2712 - accuracy: 0.5666 - val_loss: 3.5673 - val_accuracy: 0.4072\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.1498 - accuracy: 0.6172 - val_loss: 1.5118 - val_accuracy: 0.5266\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.5765 - accuracy: 0.5402 - val_loss: 43711.3359 - val_accuracy: 0.0956\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.9461 - accuracy: 0.3798 - val_loss: 1.5821 - val_accuracy: 0.4224\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.6341 - accuracy: 0.4619 - val_loss: 2.5505 - val_accuracy: 0.2910\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.5345 - accuracy: 0.4919 - val_loss: 35.0205 - val_accuracy: 0.2684\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.3705 - accuracy: 0.5313 - val_loss: 1.4651 - val_accuracy: 0.4858\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.2353 - accuracy: 0.5802 - val_loss: 7.0949 - val_accuracy: 0.4858\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.0890 - accuracy: 0.6278 - val_loss: 1.8918 - val_accuracy: 0.4428\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.0284 - accuracy: 0.6623 - val_loss: 1.5510 - val_accuracy: 0.5912\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.1144 - accuracy: 0.6331 - val_loss: 3.1806 - val_accuracy: 0.5792\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.0586 - accuracy: 0.6466 - val_loss: 1.8003 - val_accuracy: 0.4052\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 1.0575 - accuracy: 0.6576 - val_loss: 1.4240 - val_accuracy: 0.5334\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.4100 - accuracy: 0.5622 - val_loss: 4.7663 - val_accuracy: 0.4818\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.0181 - accuracy: 0.6588 - val_loss: 97.4230 - val_accuracy: 0.2338\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.1331 - accuracy: 0.6278 - val_loss: 1.1604 - val_accuracy: 0.5974\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 0.8694 - accuracy: 0.7096 - val_loss: 3.0198 - val_accuracy: 0.1976\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 10s 39ms/step - loss: 1.7132 - accuracy: 0.4382 - val_loss: 1.4479 - val_accuracy: 0.4964\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.5049 - accuracy: 0.5101 - val_loss: 1.6575 - val_accuracy: 0.4022\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.3168 - accuracy: 0.5597 - val_loss: 1.2596 - val_accuracy: 0.5504\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.0892 - accuracy: 0.6295 - val_loss: 22.1234 - val_accuracy: 0.4948\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 1.0628 - accuracy: 0.6490 - val_loss: 1.1058 - val_accuracy: 0.6088\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.9917 - accuracy: 0.6688 - val_loss: 1.2919 - val_accuracy: 0.5700\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 1.1373 - accuracy: 0.6198 - val_loss: 1.0746 - val_accuracy: 0.6266\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.8431 - accuracy: 0.7169 - val_loss: 1.2363 - val_accuracy: 0.6004\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 1.3161 - accuracy: 0.5974\n",
      "Epoch 1/28\n",
      "266/266 [==============================] - 17s 44ms/step - loss: 2.3599 - accuracy: 0.2824 - val_loss: 3.2624 - val_accuracy: 0.0976\n",
      "Epoch 2/28\n",
      "266/266 [==============================] - 11s 41ms/step - loss: 1.6969 - accuracy: 0.4272 - val_loss: 2.2704 - val_accuracy: 0.2908\n",
      "Epoch 3/28\n",
      "266/266 [==============================] - 11s 41ms/step - loss: 1.6227 - accuracy: 0.4577 - val_loss: 1.6738 - val_accuracy: 0.4084\n",
      "Epoch 4/28\n",
      "266/266 [==============================] - 11s 41ms/step - loss: 1.4366 - accuracy: 0.5038 - val_loss: 1.8593 - val_accuracy: 0.4068\n",
      "Epoch 5/28\n",
      "266/266 [==============================] - 11s 41ms/step - loss: 1.3569 - accuracy: 0.5479 - val_loss: 1.4771 - val_accuracy: 0.5052\n",
      "Epoch 6/28\n",
      "266/266 [==============================] - 10s 38ms/step - loss: 1.2424 - accuracy: 0.5673 - val_loss: 1.6487 - val_accuracy: 0.4696\n",
      "Epoch 7/28\n",
      "266/266 [==============================] - 10s 38ms/step - loss: 1.3843 - accuracy: 0.5417 - val_loss: 1.7301 - val_accuracy: 0.5328\n",
      "Epoch 8/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.0903 - accuracy: 0.6198 - val_loss: 3.0491 - val_accuracy: 0.2246\n",
      "Epoch 9/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.1444 - accuracy: 0.6056 - val_loss: 2.1054 - val_accuracy: 0.3670\n",
      "Epoch 10/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.1322 - accuracy: 0.6268 - val_loss: 13.8498 - val_accuracy: 0.1802\n",
      "Epoch 11/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.5971 - accuracy: 0.5085 - val_loss: 1.7355 - val_accuracy: 0.4090\n",
      "Epoch 12/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.2544 - accuracy: 0.5676 - val_loss: 1.2032 - val_accuracy: 0.5698\n",
      "Epoch 13/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.2683 - accuracy: 0.6129 - val_loss: 1.4219 - val_accuracy: 0.5396\n",
      "Epoch 14/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.0516 - accuracy: 0.6709 - val_loss: 15.4844 - val_accuracy: 0.2204\n",
      "Epoch 15/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.3417 - accuracy: 0.5682 - val_loss: 1.3541 - val_accuracy: 0.5348\n",
      "Epoch 16/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.2063 - accuracy: 0.5883 - val_loss: 1.5885 - val_accuracy: 0.5028\n",
      "Epoch 17/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.1889 - accuracy: 0.6107 - val_loss: 2.0482 - val_accuracy: 0.3692\n",
      "Epoch 18/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.0658 - accuracy: 0.6449 - val_loss: 9.9747 - val_accuracy: 0.1832\n",
      "Epoch 19/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.3629 - accuracy: 0.5898 - val_loss: 4.1866 - val_accuracy: 0.4924\n",
      "Epoch 20/28\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.0602 - accuracy: 0.6604 - val_loss: 1.1574 - val_accuracy: 0.6180\n",
      "Epoch 21/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.8611 - accuracy: 0.7153 - val_loss: 1.2483 - val_accuracy: 0.6188\n",
      "Epoch 22/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.7328 - accuracy: 0.7487 - val_loss: 2.6654 - val_accuracy: 0.3194\n",
      "Epoch 23/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.8926 - accuracy: 0.7110 - val_loss: 1.1482 - val_accuracy: 0.6502\n",
      "Epoch 24/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.6832 - accuracy: 0.7843 - val_loss: 3.6914 - val_accuracy: 0.5216\n",
      "Epoch 25/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.0943 - accuracy: 0.6642 - val_loss: 457.9719 - val_accuracy: 0.1090\n",
      "Epoch 26/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.1279 - accuracy: 0.6314 - val_loss: 1.2529 - val_accuracy: 0.5730\n",
      "Epoch 27/28\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 1.1995 - accuracy: 0.6008 - val_loss: 1.8424 - val_accuracy: 0.4014\n",
      "Epoch 28/28\n",
      "266/266 [==============================] - 11s 41ms/step - loss: 1.2072 - accuracy: 0.5872 - val_loss: 2.0349 - val_accuracy: 0.3324\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 2.0015 - accuracy: 0.3456\n",
      "Epoch 1/26\n",
      "282/282 [==============================] - 18s 46ms/step - loss: 2.3932 - accuracy: 0.2794 - val_loss: 3.0548 - val_accuracy: 0.1120\n",
      "Epoch 2/26\n",
      "282/282 [==============================] - 12s 42ms/step - loss: 1.5891 - accuracy: 0.4496 - val_loss: 4.3813 - val_accuracy: 0.3386\n",
      "Epoch 3/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.7534 - accuracy: 0.3946 - val_loss: 1.6811 - val_accuracy: 0.3916\n",
      "Epoch 4/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.4812 - accuracy: 0.5044 - val_loss: 4.6735 - val_accuracy: 0.2166\n",
      "Epoch 5/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.4047 - accuracy: 0.5304 - val_loss: 2.4877 - val_accuracy: 0.1938\n",
      "Epoch 6/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.5138 - accuracy: 0.4805 - val_loss: 1.3965 - val_accuracy: 0.5060\n",
      "Epoch 7/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 1.4584 - accuracy: 0.5269 - val_loss: 120.2013 - val_accuracy: 0.2574\n",
      "Epoch 8/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.3410 - accuracy: 0.5514 - val_loss: 9.0868 - val_accuracy: 0.3008\n",
      "Epoch 9/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.2837 - accuracy: 0.5913 - val_loss: 2029.5878 - val_accuracy: 0.0956\n",
      "Epoch 10/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.4120 - accuracy: 0.5326 - val_loss: 5.6523 - val_accuracy: 0.3026\n",
      "Epoch 11/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 1.3560 - accuracy: 0.5509 - val_loss: 25.6861 - val_accuracy: 0.3850\n",
      "Epoch 12/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 1.0801 - accuracy: 0.6411 - val_loss: 1.1884 - val_accuracy: 0.5876\n",
      "Epoch 13/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 0.9303 - accuracy: 0.6871 - val_loss: 1.5067 - val_accuracy: 0.5236\n",
      "Epoch 14/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 0.8618 - accuracy: 0.7206 - val_loss: 1.4603 - val_accuracy: 0.5614\n",
      "Epoch 15/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 0.7692 - accuracy: 0.7514 - val_loss: 1.2577 - val_accuracy: 0.6160\n",
      "Epoch 16/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 0.8033 - accuracy: 0.7539 - val_loss: 3.5372 - val_accuracy: 0.1998\n",
      "Epoch 17/26\n",
      "282/282 [==============================] - 12s 42ms/step - loss: 1.2264 - accuracy: 0.6117 - val_loss: 2.2695 - val_accuracy: 0.3094\n",
      "Epoch 18/26\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 1.4930 - accuracy: 0.5582 - val_loss: 1.8587 - val_accuracy: 0.4240\n",
      "Epoch 19/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 1.3621 - accuracy: 0.5353 - val_loss: 1.6298 - val_accuracy: 0.4552\n",
      "Epoch 20/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 1.0811 - accuracy: 0.6308 - val_loss: 1.3326 - val_accuracy: 0.5430\n",
      "Epoch 21/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 1.0258 - accuracy: 0.6529 - val_loss: 2.2704 - val_accuracy: 0.2412\n",
      "Epoch 22/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 1.4510 - accuracy: 0.5114 - val_loss: 31.7377 - val_accuracy: 0.1170\n",
      "Epoch 23/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 1.3626 - accuracy: 0.5288 - val_loss: 3.0761 - val_accuracy: 0.2342\n",
      "Epoch 24/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 1.1358 - accuracy: 0.6187 - val_loss: 1.1506 - val_accuracy: 0.5986\n",
      "Epoch 25/26\n",
      "282/282 [==============================] - 11s 41ms/step - loss: 1.0451 - accuracy: 0.6589 - val_loss: 1.3979 - val_accuracy: 0.5534\n",
      "Epoch 26/26\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 0.9111 - accuracy: 0.6945 - val_loss: 1.0402 - val_accuracy: 0.6466\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 1.0493 - accuracy: 0.6454\n",
      "Epoch 1/25\n",
      "297/297 [==============================] - 17s 42ms/step - loss: 2.3604 - accuracy: 0.2833 - val_loss: 2.8217 - val_accuracy: 0.1120\n",
      "Epoch 2/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.5774 - accuracy: 0.4589 - val_loss: 39.8329 - val_accuracy: 0.3074\n",
      "Epoch 3/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6998 - accuracy: 0.4453 - val_loss: 4.0416 - val_accuracy: 0.3576\n",
      "Epoch 4/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.6451 - accuracy: 0.4554 - val_loss: 170.8542 - val_accuracy: 0.1106\n",
      "Epoch 5/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.9573 - accuracy: 0.3496 - val_loss: 2.0053 - val_accuracy: 0.3016\n",
      "Epoch 6/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6218 - accuracy: 0.4396 - val_loss: 1.5730 - val_accuracy: 0.4660\n",
      "Epoch 7/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.4670 - accuracy: 0.4994 - val_loss: 1.7829 - val_accuracy: 0.3712\n",
      "Epoch 8/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.5331 - accuracy: 0.4918 - val_loss: 5.2006 - val_accuracy: 0.3412\n",
      "Epoch 9/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.4324 - accuracy: 0.5084 - val_loss: 2.8397 - val_accuracy: 0.1088\n",
      "Epoch 10/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6041 - accuracy: 0.4627 - val_loss: 628.9406 - val_accuracy: 0.1020\n",
      "Epoch 11/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.8087 - accuracy: 0.3955 - val_loss: 2.8806 - val_accuracy: 0.1982\n",
      "Epoch 12/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.7531 - accuracy: 0.4059 - val_loss: 1.4082 - val_accuracy: 0.4872\n",
      "Epoch 13/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.4717 - accuracy: 0.5059 - val_loss: 1.7821 - val_accuracy: 0.3624\n",
      "Epoch 14/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6681 - accuracy: 0.4634 - val_loss: 1.6139 - val_accuracy: 0.4244\n",
      "Epoch 15/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6403 - accuracy: 0.4603 - val_loss: 2.9619 - val_accuracy: 0.2908\n",
      "Epoch 16/25\n",
      "297/297 [==============================] - 11s 39ms/step - loss: 1.5937 - accuracy: 0.4720 - val_loss: 1.5706 - val_accuracy: 0.4582\n",
      "Epoch 17/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.6109 - accuracy: 0.4729 - val_loss: 2.2435 - val_accuracy: 0.2838\n",
      "Epoch 18/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.5366 - accuracy: 0.4913 - val_loss: 1.7781 - val_accuracy: 0.3902\n",
      "Epoch 19/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.4118 - accuracy: 0.5309 - val_loss: 3.7308 - val_accuracy: 0.2538\n",
      "Epoch 20/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.4044 - accuracy: 0.5217 - val_loss: 2.5758 - val_accuracy: 0.4880\n",
      "Epoch 21/25\n",
      "297/297 [==============================] - 11s 39ms/step - loss: 1.2830 - accuracy: 0.5705 - val_loss: 25.8930 - val_accuracy: 0.2446\n",
      "Epoch 22/25\n",
      "297/297 [==============================] - 11s 39ms/step - loss: 1.4476 - accuracy: 0.5197 - val_loss: 1.8914 - val_accuracy: 0.3934\n",
      "Epoch 23/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.4667 - accuracy: 0.5180 - val_loss: 9.8994 - val_accuracy: 0.3552\n",
      "Epoch 24/25\n",
      "297/297 [==============================] - 11s 38ms/step - loss: 1.3090 - accuracy: 0.5504 - val_loss: 2.4568 - val_accuracy: 0.2978\n",
      "Epoch 25/25\n",
      "297/297 [==============================] - 12s 39ms/step - loss: 1.3305 - accuracy: 0.5497 - val_loss: 1.7553 - val_accuracy: 0.4070\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 1.7823 - accuracy: 0.4038\n",
      "Epoch 1/24\n",
      "313/313 [==============================] - 19s 44ms/step - loss: 2.3633 - accuracy: 0.2910 - val_loss: 2.7468 - val_accuracy: 0.1802\n",
      "Epoch 2/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.7325 - accuracy: 0.4230 - val_loss: 1.9123 - val_accuracy: 0.3860\n",
      "Epoch 3/24\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 1.5171 - accuracy: 0.4991 - val_loss: 2.6510 - val_accuracy: 0.3422\n",
      "Epoch 4/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.4064 - accuracy: 0.5275 - val_loss: 23.0296 - val_accuracy: 0.3692\n",
      "Epoch 5/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.5485 - accuracy: 0.4781 - val_loss: 10.3745 - val_accuracy: 0.1440\n",
      "Epoch 6/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.7798 - accuracy: 0.3897 - val_loss: 1.8669 - val_accuracy: 0.3232\n",
      "Epoch 7/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.7291 - accuracy: 0.4259 - val_loss: 3.2705 - val_accuracy: 0.2754\n",
      "Epoch 8/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.5632 - accuracy: 0.4752 - val_loss: 4.7219 - val_accuracy: 0.1290\n",
      "Epoch 9/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.6613 - accuracy: 0.4492 - val_loss: 1.5809 - val_accuracy: 0.4392\n",
      "Epoch 10/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.4063 - accuracy: 0.5236 - val_loss: 4.1201 - val_accuracy: 0.3176\n",
      "Epoch 11/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.3411 - accuracy: 0.5392 - val_loss: 1.9938 - val_accuracy: 0.3360\n",
      "Epoch 12/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.6008 - accuracy: 0.4681 - val_loss: 62.1634 - val_accuracy: 0.1268\n",
      "Epoch 13/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.6702 - accuracy: 0.4560 - val_loss: 3.0632 - val_accuracy: 0.3954\n",
      "Epoch 14/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.4251 - accuracy: 0.5296 - val_loss: 1.3950 - val_accuracy: 0.5018\n",
      "Epoch 15/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.3576 - accuracy: 0.5450 - val_loss: 2.7392 - val_accuracy: 0.2572\n",
      "Epoch 16/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.6077 - accuracy: 0.4674 - val_loss: 1.9484 - val_accuracy: 0.3114\n",
      "Epoch 17/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.8586 - accuracy: 0.3618 - val_loss: 1.6762 - val_accuracy: 0.3978\n",
      "Epoch 18/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.5681 - accuracy: 0.4396 - val_loss: 1.4279 - val_accuracy: 0.4758\n",
      "Epoch 19/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.4985 - accuracy: 0.4771 - val_loss: 1.5279 - val_accuracy: 0.4720\n",
      "Epoch 20/24\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 1.3860 - accuracy: 0.5132 - val_loss: 1.5814 - val_accuracy: 0.4696\n",
      "Epoch 21/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.3338 - accuracy: 0.5476 - val_loss: 1.3663 - val_accuracy: 0.5178\n",
      "Epoch 22/24\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.2664 - accuracy: 0.5629 - val_loss: 2.0606 - val_accuracy: 0.3436\n",
      "Epoch 23/24\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.5310 - accuracy: 0.4908 - val_loss: 1.2765 - val_accuracy: 0.5368\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step - loss: 1.3448 - accuracy: 0.5684 - val_loss: 34.2925 - val_accuracy: 0.5108\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 46.2054 - accuracy: 0.5144\n",
      "Epoch 1/22\n",
      "329/329 [==============================] - 19s 42ms/step - loss: 2.3451 - accuracy: 0.2929 - val_loss: 3.3760 - val_accuracy: 0.1392\n",
      "Epoch 2/22\n",
      "329/329 [==============================] - 13s 41ms/step - loss: 1.5923 - accuracy: 0.4549 - val_loss: 273.6581 - val_accuracy: 0.1632\n",
      "Epoch 3/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.9024 - accuracy: 0.3557 - val_loss: 1.5437 - val_accuracy: 0.4744\n",
      "Epoch 4/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.5805 - accuracy: 0.4681 - val_loss: 1.9618 - val_accuracy: 0.3440\n",
      "Epoch 5/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.3661 - accuracy: 0.5306 - val_loss: 48.3123 - val_accuracy: 0.2324\n",
      "Epoch 6/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.4346 - accuracy: 0.5249 - val_loss: 1.3225 - val_accuracy: 0.5466\n",
      "Epoch 7/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.5238 - accuracy: 0.5362 - val_loss: 1.3588 - val_accuracy: 0.5206\n",
      "Epoch 8/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.3451 - accuracy: 0.5594 - val_loss: 74.6954 - val_accuracy: 0.2554\n",
      "Epoch 9/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.6875 - accuracy: 0.4492 - val_loss: 3.9590 - val_accuracy: 0.3014\n",
      "Epoch 10/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.6977 - accuracy: 0.4456 - val_loss: 1.8906 - val_accuracy: 0.4558\n",
      "Epoch 11/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.3555 - accuracy: 0.5442 - val_loss: 1.4658 - val_accuracy: 0.4776\n",
      "Epoch 12/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.2845 - accuracy: 0.5775 - val_loss: 1.4566 - val_accuracy: 0.5174\n",
      "Epoch 13/22\n",
      "329/329 [==============================] - 13s 41ms/step - loss: 1.1883 - accuracy: 0.6060 - val_loss: 1.2881 - val_accuracy: 0.5550\n",
      "Epoch 14/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.1444 - accuracy: 0.6320 - val_loss: 14.2934 - val_accuracy: 0.4528\n",
      "Epoch 15/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 1.2372 - accuracy: 0.5847 - val_loss: 1.0393 - val_accuracy: 0.6238\n",
      "Epoch 16/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.0627 - accuracy: 0.6523 - val_loss: 2.1961 - val_accuracy: 0.3262\n",
      "Epoch 17/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 1.2336 - accuracy: 0.6055 - val_loss: 1.2782 - val_accuracy: 0.5534\n",
      "Epoch 18/22\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 1.1413 - accuracy: 0.6343 - val_loss: 1.3119 - val_accuracy: 0.5718\n",
      "Epoch 19/22\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.8796 - accuracy: 0.7159 - val_loss: 2.7851 - val_accuracy: 0.5914\n",
      "Epoch 20/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.7893 - accuracy: 0.7487 - val_loss: 1.3006 - val_accuracy: 0.6472\n",
      "Epoch 21/22\n",
      "329/329 [==============================] - 13s 41ms/step - loss: 0.7749 - accuracy: 0.7561 - val_loss: 3.4523 - val_accuracy: 0.6662\n",
      "Epoch 22/22\n",
      "329/329 [==============================] - 13s 40ms/step - loss: 0.6396 - accuracy: 0.8017 - val_loss: 1.9988 - val_accuracy: 0.4798\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 2.0336 - accuracy: 0.4854\n",
      "Epoch 1/21\n",
      "344/344 [==============================] - 19s 41ms/step - loss: 2.3525 - accuracy: 0.3004 - val_loss: 2.6857 - val_accuracy: 0.2056\n",
      "Epoch 2/21\n",
      "344/344 [==============================] - 13s 39ms/step - loss: 1.6554 - accuracy: 0.4527 - val_loss: 2.3695 - val_accuracy: 0.3314\n",
      "Epoch 3/21\n",
      "344/344 [==============================] - 13s 39ms/step - loss: 1.4911 - accuracy: 0.5051 - val_loss: 3.6157 - val_accuracy: 0.4102\n",
      "Epoch 4/21\n",
      "344/344 [==============================] - 13s 39ms/step - loss: 1.6920 - accuracy: 0.4878 - val_loss: 1.7811 - val_accuracy: 0.4484\n",
      "Epoch 5/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.3799 - accuracy: 0.5655 - val_loss: 1.5845 - val_accuracy: 0.4856\n",
      "Epoch 6/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.1652 - accuracy: 0.6201 - val_loss: 9.1324 - val_accuracy: 0.1412\n",
      "Epoch 7/21\n",
      "344/344 [==============================] - 14s 41ms/step - loss: 1.5857 - accuracy: 0.4987 - val_loss: 60.4577 - val_accuracy: 0.2442\n",
      "Epoch 8/21\n",
      "344/344 [==============================] - 13s 39ms/step - loss: 1.5610 - accuracy: 0.5061 - val_loss: 125.4261 - val_accuracy: 0.1194\n",
      "Epoch 9/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.6102 - accuracy: 0.4723 - val_loss: 1.4556 - val_accuracy: 0.4672\n",
      "Epoch 10/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.2656 - accuracy: 0.5792 - val_loss: 1.9543 - val_accuracy: 0.3714\n",
      "Epoch 11/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.2324 - accuracy: 0.6057 - val_loss: 1.2513 - val_accuracy: 0.5742\n",
      "Epoch 12/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.0427 - accuracy: 0.6660 - val_loss: 34.6252 - val_accuracy: 0.1546\n",
      "Epoch 13/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.0272 - accuracy: 0.6599 - val_loss: 2.3337 - val_accuracy: 0.4844\n",
      "Epoch 14/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 0.8686 - accuracy: 0.7129 - val_loss: 6.3441 - val_accuracy: 0.3212\n",
      "Epoch 15/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 0.9984 - accuracy: 0.6607 - val_loss: 3.3571 - val_accuracy: 0.2716\n",
      "Epoch 16/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 0.9719 - accuracy: 0.6715 - val_loss: 128.8291 - val_accuracy: 0.2316\n",
      "Epoch 17/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.3346 - accuracy: 0.5748 - val_loss: 1.1491 - val_accuracy: 0.6014\n",
      "Epoch 18/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.0652 - accuracy: 0.6588 - val_loss: 1.5685 - val_accuracy: 0.5402\n",
      "Epoch 19/21\n",
      "344/344 [==============================] - 14s 41ms/step - loss: 0.9679 - accuracy: 0.6779 - val_loss: 1.1312 - val_accuracy: 0.6300\n",
      "Epoch 20/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 0.7667 - accuracy: 0.7431 - val_loss: 23.5408 - val_accuracy: 0.1230\n",
      "Epoch 21/21\n",
      "344/344 [==============================] - 14s 40ms/step - loss: 1.0704 - accuracy: 0.6335 - val_loss: 1.0143 - val_accuracy: 0.6546\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 1.0435 - accuracy: 0.6464\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 20s 43ms/step - loss: 2.3085 - accuracy: 0.3041 - val_loss: 3.7707 - val_accuracy: 0.1016\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 15s 40ms/step - loss: 1.5972 - accuracy: 0.4452 - val_loss: 407938.0312 - val_accuracy: 0.1048\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 15s 41ms/step - loss: 1.9700 - accuracy: 0.3402 - val_loss: 2114.6267 - val_accuracy: 0.1118\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 1.7012 - accuracy: 0.4422 - val_loss: 4.4419 - val_accuracy: 0.2330\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 1.4816 - accuracy: 0.5132 - val_loss: 3.1297 - val_accuracy: 0.2220\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.5128 - accuracy: 0.5111 - val_loss: 2.2179 - val_accuracy: 0.2998\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.6004 - accuracy: 0.4569 - val_loss: 1.7115 - val_accuracy: 0.4212\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.3728 - accuracy: 0.5250 - val_loss: 51.1255 - val_accuracy: 0.3066\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 15s 40ms/step - loss: 1.3592 - accuracy: 0.5315 - val_loss: 1.9467 - val_accuracy: 0.4524\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.1819 - accuracy: 0.5904 - val_loss: 1.1825 - val_accuracy: 0.5786\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 1.1998 - accuracy: 0.5926 - val_loss: 1.4435 - val_accuracy: 0.5120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.1029 - accuracy: 0.6201 - val_loss: 1.1620 - val_accuracy: 0.5848\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.0577 - accuracy: 0.6386 - val_loss: 3.9741 - val_accuracy: 0.1504\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 1.8507 - accuracy: 0.3948 - val_loss: 1.7800 - val_accuracy: 0.4130\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 1.3316 - accuracy: 0.5375 - val_loss: 1.3123 - val_accuracy: 0.5318\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.0917 - accuracy: 0.6193 - val_loss: 1.6056 - val_accuracy: 0.5104\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 15s 40ms/step - loss: 1.0682 - accuracy: 0.6314 - val_loss: 1.6886 - val_accuracy: 0.4586\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 1.1100 - accuracy: 0.6086 - val_loss: 1.2568 - val_accuracy: 0.5546\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.8706 - accuracy: 0.6949 - val_loss: 1.0034 - val_accuracy: 0.6366\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 0.7392 - accuracy: 0.7403 - val_loss: 0.9956 - val_accuracy: 0.6422\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 1.0238 - accuracy: 0.6432\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = training_fit_loop(model=model_0,\n",
    "                     model_params=((32, 32, 3), tf.keras.optimizers.Adam, tf.keras.losses.CategoricalCrossentropy(), [\"accuracy\"]),\n",
    "                     data_step=2000,\n",
    "                     n=20,\n",
    "                     data_loading_params=(\"cifar10\", 128, mask_to_categorical, False, False, \"test\"),\n",
    "                     start_data=8000,\n",
    "                     save_df=os.getcwd()[:-len(\"tests\")] + \"results_df/\", \n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R Exp</th>\n",
       "      <th>Exp function fit</th>\n",
       "      <th>Exp: Mean power constant</th>\n",
       "      <th>Exp: Root of variance</th>\n",
       "      <th>Exp: R value of fit</th>\n",
       "      <th>R PL</th>\n",
       "      <th>PL function fit</th>\n",
       "      <th>PL: Mean power constant</th>\n",
       "      <th>PL: Root of variance</th>\n",
       "      <th>PL: R value of fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment 1:</th>\n",
       "      <td>0.969349</td>\n",
       "      <td>(1.378047389033095, 0.00013869609017929036, 0....</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969349</td>\n",
       "      <td>0.99362</td>\n",
       "      <td>(1995.703846090993, 0.9116801751027342, 0.5324...</td>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R Exp                                   Exp function fit  \\\n",
       "Experiment 1:  0.969349  (1.378047389033095, 0.00013869609017929036, 0....   \n",
       "\n",
       "               Exp: Mean power constant  Exp: Root of variance  \\\n",
       "Experiment 1:                  0.000139                    0.0   \n",
       "\n",
       "               Exp: R value of fit    R PL  \\\n",
       "Experiment 1:              0.969349  0.99362   \n",
       "\n",
       "                                                 PL function fit  \\\n",
       "Experiment 1:  (1995.703846090993, 0.9116801751027342, 0.5324...   \n",
       "\n",
       "               PL: Mean power constant  PL: Root of variance  \\\n",
       "Experiment 1:                  0.91168                   0.0   \n",
       "\n",
       "               PL: R value of fit  \n",
       "Experiment 1:              0.99362  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_pickle(os.getcwd()[:-len(\"tests\")] + \"results_df/07_07_2022_-16_44_06_experiment_1\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.378047389033095, 0.00013869609017929036, 0.6652142013614948)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"Exp function fit\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1995.703846090993, 0.9116801751027342, 0.5324319887493496)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"PL function fit\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without loop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras import regularizers\n",
    "def cnn_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Conv layer\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Second Conv layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Third, fourth, fifth convolution layer\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Fully Connected layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
